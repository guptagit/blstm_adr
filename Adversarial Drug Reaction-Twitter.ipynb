{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-f43faf411e5b>, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-f43faf411e5b>\"\u001b[1;36m, line \u001b[1;32m73\u001b[0m\n\u001b[1;33m    f1 = f1_score(y_true, y_probs >= th)*1)\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import csv\n",
    "import theano.tensor as T\n",
    "import os.path\n",
    "from nltk.collocations import *\n",
    "from optparse import OptionParser\n",
    "from collections import Counter\n",
    "from copy import copy\n",
    "import cPickle\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "from keras.layers.convolutional import MaxPooling1D, Convolution1D\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.engine.training import slice_X\n",
    "from keras.layers.core import Layer, Dense, Dropout, Activation,\\\n",
    "    Reshape, Flatten, Lambda\n",
    "from keras.regularizers import Regularizer\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "from IPython.utils.io import CapturedIO\n",
    "from gensim.models import Word2Vec\n",
    "from pkg_resources import resource_filename\n",
    "import utils\n",
    "import datasets\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Yoon Kim's tokenization\n",
    "def my_process(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^\\w(),|!?\\'\\`\\:\\-\\.;\\$%#]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" is\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" have\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" not\", string)\n",
    "    string = re.sub(r\"\\'re\", \" are\", string)\n",
    "    string = re.sub(r\"\\'d\", \" would\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" will\", string)\n",
    "    string = re.sub(r\"(?<=\\w)\\.\\.\\.\", \" ... \", string)\n",
    "    string = re.sub(r\"(?<=\\w)\\.\", \" . \", string)\n",
    "    string = re.sub(r\"(?<=\\w),\", \" , \", string)\n",
    "    string = re.sub(r\"(?<=\\w);\", \" ; \", string)\n",
    "    string = re.sub(r\"(?<=\\w)!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\((?=\\w)\", \" ( \", string)\n",
    "    string = re.sub(r\"(?<=\\w)\\)\", \" ) \", string)\n",
    "    string = re.sub(r\"(?<=\\w)\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip()\n",
    "\n",
    "def mixed_score(y_true, y_probs):\n",
    "    thresholds = sorted(unique(y_probs))\n",
    "    max_f1, best_threshold = 0, 0\n",
    "    for th in thresholds:\n",
    "        f1 = f1_score(y_true, y_probs >= th)*1)\n",
    "        if f1 > max_f1:\n",
    "            max_f1 = f1\n",
    "            best_th = th\n",
    "    th = best_th    \n",
    "    return {\n",
    "        \"precision\": y_true[y_probs >= th].sum()*1./(y_probs >= th).sum(),\n",
    "        \"recall\": y_true[y_probs >= th].sum()*1./y_true.sum(),\n",
    "        \"f1\": f1_score(y_true, (y_probs >= th)*1),\n",
    "        \"auc\": roc_auc_score(y_true, y_probs)\n",
    "    }\n",
    "\n",
    "# This function chooses the best threshold based on f1 of validation.\n",
    "def seq_score(model, X, y):\n",
    "    val_split = model.last_fit_params.get('validation_split', 0.)\n",
    "    split_at = int(model.last_fit_X.shape[0] * (1. - val_split))\n",
    "    X_val, y_val = model.last_fit_X[split_at:], model.last_fit_y[split_at:]\n",
    "    val_probs = model.predict(X_val).flatten()\n",
    "    thresholds = sorted(unique(val_probs))\n",
    "    max_f1, best_threshold = 0, 0\n",
    "    for threshold in thresholds:\n",
    "        f1 = f1_score(y_val, (val_probs >= threshold)*1)\n",
    "        if f1 > max_f1:\n",
    "            max_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return mixed_score(y, model.predict(X).flatten(), best_threshold)\n",
    "    \n",
    "# Same as seq_f1 but for graph model\n",
    "def graph_score(model, data):\n",
    "    val_split = model.last_fit_params.get('validation_split', 0.)\n",
    "    split_at = int(model.last_fit_data['output'].shape[0] * (1. - val_split))\n",
    "    data_val = {k: slice_X(v, split_at) for k, v in model.last_fit_data.items()}\n",
    "    val_probs = model.predict(data_val)['output'].flatten()\n",
    "    thresholds = sorted(unique(val_probs))\n",
    "    max_f1, best_threshold = 0, 0\n",
    "    for threshold in thresholds:\n",
    "        f1 = f1_score(data_val['output'], (val_probs >= threshold)*1)\n",
    "        if f1 > max_f1:\n",
    "            max_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return mixed_score(data['output'], \n",
    "                       model.predict(data)['output'].flatten(), \n",
    "                       best_threshold)\n",
    "\n",
    "def seq_auc(model, X, y):\n",
    "    preds = model.predict(X).flatten()\n",
    "    return roc_auc_score(y, preds)\n",
    "    \n",
    "def graph_auc(model, data):\n",
    "    preds = model.predict(data)['output'].flatten()\n",
    "    return roc_auc_score(data['output'], preds)\n",
    "\n",
    "seq_eval_f = seq_score\n",
    "graph_eval_f = graph_score\n",
    "results = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mixed_score(y_true, y_probs, th):  \n",
    "    y_true, y_probs = asarray(y_true), asarray(y_probs)\n",
    "    return {\n",
    "        \"precision\": y_true[y_probs >= th].sum()*1./(y_probs >= th).sum(),\n",
    "        \"recall\": y_true[y_probs >= th].sum()*1./y_true.sum(),\n",
    "        \"f1\": f1_score(y_true, (y_probs >= th)*1),\n",
    "        \"auc\": roc_auc_score(y_true, y_probs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ADR Twitter data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/trung/data/psb2016/\"\n",
    "tweets, clean_tweets, labels = [], [], []\n",
    "with open(os.path.join(data_path, 'tweets.txt')) as f:\n",
    "    for line in f:\n",
    "        user_id, tweet_id, label, tweet = line.strip().split('\\t')\n",
    "        tweets.append(unidecode(tweet.decode('utf-8')))\n",
    "        labels.append(int(label))\n",
    "    \n",
    "np.random.seed(0)\n",
    "# Shuffle the data as Keras won't shuffle validation data.\n",
    "# This can make the training ends early as we are using\n",
    "# early stop for regularisation.\n",
    "idx = np.random.permutation(len(tweets))\n",
    "tweets, labels = asarray(tweets)[idx], asarray(labels)[idx]\n",
    "skf = list(StratifiedKFold(labels, n_folds=10))\n",
    "texts = asarray(tweets, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5108,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from zhang_adr.concept_matching import run_cm\n",
    "from zhang_adr.maxent_tfidf import run_tfidf\n",
    "from zhang_adr.maxent_nblcr import run_nblcr\n",
    "from zhang_adr.maxent_we import run_we\n",
    "from zhang_adr.tweetnlp import tweet_tagger\n",
    "from zhang_adr.preprocess import clean_tweet\n",
    "\n",
    "tokens, tags = tweet_tagger.runtagger_parse(texts)\n",
    "zhang_clean_texts = []\n",
    "for token, tag in zip(tokens, tags):\n",
    "    zhang_clean_texts.append(clean_tweet(token, tag))\n",
    "zhang_clean_texts = asarray(zhang_clean_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Fold 1:\n",
      "### Fold 2:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 3:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 4:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 5:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 6:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 7:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 8:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 9:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Fold 10:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results = results[results['model'] != 'CM']\n",
    "results = results[results['model'] != 'ME-TFIDF']\n",
    "results = results[results['model'] != 'ME-NBLCR']\n",
    "results = results[results['model'] != 'ME-WE']\n",
    "clf = LogisticRegression(class_weight=\"auto\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for i, (train_idx, test_idx) in enumerate(skf, 1):\n",
    "        print \"### Fold {}:\".format(i)\n",
    "        train, test = [], []\n",
    "        for train_id in train_idx:\n",
    "            train.append({\"id\": None, \"label\": labels[train_id], \"text\": zhang_clean_texts[train_id]})\n",
    "        train = pandas.DataFrame(train)\n",
    "        for test_id in test_idx:\n",
    "            test.append({\"id\": None, \"label\": labels[test_id], \"text\": zhang_clean_texts[test_id]})\n",
    "        test = pandas.DataFrame(test)\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        y_pred_cm = run_cm(train, test, resource_filename('zhang_adr', 'data/ADR-lexicon.txt'))\n",
    "        result = mixed_score(test['label'].values, y_pred_cm, 0.5)\n",
    "        result['model'] = 'CM'\n",
    "        results = pandas.concat([results, pandas.DataFrame([result])])\n",
    "\n",
    "        _, y_prob_tfidf = run_tfidf(train, test, grams='123', n_dim=40000, clf=clf)\n",
    "        result = mixed_score(test['label'].values, asarray(y_prob_tfidf[:, 1]), 0.5)\n",
    "        result['model'] = 'ME-TFIDF'\n",
    "        results = pandas.concat([results, pandas.DataFrame([result])])\n",
    "\n",
    "        _, y_prob_nblcr = run_nblcr(train, test, 'nblcr', grams='123', clf=clf)\n",
    "        result = mixed_score(test['label'].values, y_prob_nblcr[:, 1], 0.5)\n",
    "        result['model'] = 'ME-NBLCR'\n",
    "        results = pandas.concat([results, pandas.DataFrame([result])])\n",
    "\n",
    "        _, y_prob_we = run_we(train, test, resource_filename('zhang_adr', 'data/w2v_150.txt'), 150, clf=clf)\n",
    "        result = mixed_score(test['label'].values,  y_prob_we[:, 1], 0.5)\n",
    "        result['model'] = 'ME-WE'\n",
    "        results = pandas.concat([results, pandas.DataFrame([result])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>0.587609</td>\n",
       "      <td>0.230405</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>0.892208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.884428</td>\n",
       "      <td>0.507228</td>\n",
       "      <td>0.473284</td>\n",
       "      <td>0.568831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNNA</th>\n",
       "      <td>0.868821</td>\n",
       "      <td>0.494731</td>\n",
       "      <td>0.403737</td>\n",
       "      <td>0.658636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRNN</th>\n",
       "      <td>0.869807</td>\n",
       "      <td>0.507763</td>\n",
       "      <td>0.489378</td>\n",
       "      <td>0.552922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-NBLCR</th>\n",
       "      <td>0.832942</td>\n",
       "      <td>0.233311</td>\n",
       "      <td>0.791053</td>\n",
       "      <td>0.139805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-TFIDF</th>\n",
       "      <td>0.854756</td>\n",
       "      <td>0.449863</td>\n",
       "      <td>0.331677</td>\n",
       "      <td>0.700260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-WE</th>\n",
       "      <td>0.823112</td>\n",
       "      <td>0.398744</td>\n",
       "      <td>0.274590</td>\n",
       "      <td>0.728734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCNN</th>\n",
       "      <td>0.867046</td>\n",
       "      <td>0.488006</td>\n",
       "      <td>0.433383</td>\n",
       "      <td>0.586851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               auc        f1  precision    recall\n",
       "model                                            \n",
       "CM        0.587609  0.230405   0.132295  0.892208\n",
       "CNN       0.884428  0.507228   0.473284  0.568831\n",
       "CNNA      0.868821  0.494731   0.403737  0.658636\n",
       "CRNN      0.869807  0.507763   0.489378  0.552922\n",
       "ME-NBLCR  0.832942  0.233311   0.791053  0.139805\n",
       "ME-TFIDF  0.854756  0.449863   0.331677  0.700260\n",
       "ME-WE     0.823112  0.398744   0.274590  0.728734\n",
       "RCNN      0.867046  0.488006   0.433383  0.586851"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby('model').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in /home/trung/data/embeddings/glovec/tmp, ignoring all but first\n"
     ]
    }
   ],
   "source": [
    "# w2v = Word2Vec.load_word2vec_format(\n",
    "#     '/home/trung/data/embeddings/word2vec_twitter_model/word2vec_twitter_model.bin', \n",
    "#     binary=True\n",
    "# )\n",
    "\n",
    "# w2v = Word2Vec.load_word2vec_format(\n",
    "#     '/home/trung/data/embeddings/GoogleNews.bin', \n",
    "#     binary=True\n",
    "# )\n",
    "\n",
    "# w2v = Word2Vec.load_word2vec_format(\"/home/trung/data/embeddings/wlin/struc_skip_600.txt\")\n",
    "\n",
    "# w2v = Word2Vec.load_word2vec_format(\n",
    "#     resource_filename('zhang_adr', 'data/w2v_150.txt'),\n",
    "#     binary=False,\n",
    "# )\n",
    "\n",
    "w2v = Word2Vec.load_word2vec_format(\n",
    "    '/home/trung/data/embeddings/glovec/tmp',\n",
    "    binary=False\n",
    ")\n",
    "\n",
    "dim = w2v.layer1_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from zhang_adr.TextUtility import TextUtility\n",
    "\n",
    "MOST_FREQUENT_WORDS = 20000\n",
    "USE_CACHE = False\n",
    "INCLUDE_UNKNOWN_WORDS = False\n",
    "\n",
    "docs = [[w for w in TextUtility.text_to_wordlist(text)\\\n",
    "         if INCLUDE_UNKNOWN_WORDS or w in w2v.index2word]\\\n",
    "         for text in zhang_clean_texts]\n",
    "all_words = Counter([w for doc in docs for w in doc])\n",
    "top_words = sorted(all_words.items(), key=lambda t: t[1], reverse=True)\n",
    "top_words = top_words[:MOST_FREQUENT_WORDS]\n",
    "V = {w:i for i, (w, freq) in enumerate(top_words)}\n",
    "X = utils.vectorize(docs, V)\n",
    "\n",
    "# initialize embedding matrix\n",
    "my_embeddings = np.random.normal(-.25, .25, size=(X.max() + 1, dim))\n",
    "for w in V:\n",
    "    if w in w2v:\n",
    "        my_embeddings[V[w]] = w2v[w]\n",
    "        \n",
    "# set embedding of padded character as 0s.\n",
    "my_embeddings[len(V) + 1] = np.zeros((dim, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression of sum of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def T_sum(x, **kwargs):\n",
    "    import theano.tensor as T\n",
    "    return T.sum(x, axis=-2)\n",
    "    \n",
    "def mk_lr_model_f(max_len, embeddings, embedding_fixed=False, \n",
    "                  optimizer='adadelta', loss='binary_crossentropy'):\n",
    "    \n",
    "    def lr_model():\n",
    "        m = Sequential()\n",
    "        m.add((utils.FixedEmbedding if embedding_fixed else Embedding)\\\n",
    "                (*embeddings.shape, input_length=max_len, weights=[embeddings]))\n",
    "        m.add(Lambda(T_sum, output_shape=(embeddings.shape[1],)))\n",
    "        m.add(Dense(1, activation='sigmoid'))\n",
    "        m.compile(loss=loss, optimizer=optimizer, class_mode='binary')\n",
    "        return m\n",
    "    \n",
    "    return lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sequential model\n",
    "early_stopper = utils.MyEarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "scores = utils.seq_cross_validate(\n",
    "    mk_lr_model_f(X.shape[1], my_embeddings, optimizer='adadelta'),\n",
    "    X, labels, \n",
    "    skf, eval_f=seq_eval_f,\n",
    "    fit_params={\n",
    "        \"callbacks\": [early_stopper],\n",
    "        \"validation_split\": .1,\n",
    "        \"batch_size\": 50,\n",
    "        \"nb_epoch\": 100,\n",
    "    })\n",
    "results[\"my-lr-sum-embedding-dynamic-embedding\"] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # sequential model\n",
    "# early_stopper = utils.MyEarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "# model = utils.mk_yk_model_f(X.shape[1], my_embeddings, embedding_fixed=True, n_filters=300)()\n",
    "# train_idx, test_idx = skf5[0]\n",
    "# fit_params={\n",
    "#     \"callbacks\": [early_stopper],\n",
    "#     \"validation_split\": .1,\n",
    "#     \"batch_size\": 50\n",
    "# }\n",
    "# model.fit(X[train_idx], labels[train_idx], **fit_params)\n",
    "\n",
    "# idx = test_idx[(model.predict(X[test_idx]) >= 0.5).flatten()*1 != labels[test_idx]]\n",
    "# wrongs = pandas.DataFrame(data={\"y\": labels[idx], \"docs\": asarray(docs)[idx], \n",
    "#                                 \"zhang_clean_texts\": zhang_clean_texts[idx],\n",
    "#                                 \"texts\": texts[idx]})\n",
    "# wrongs.to_csv('incorrect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4136 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.3907 - val_loss: 0.3671\n",
      "Epoch 2/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.3206 - val_loss: 0.3437\n",
      "Epoch 3/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.2903 - val_loss: 0.3237\n",
      "Epoch 4/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.2607 - val_loss: 0.3025\n",
      "Epoch 5/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.2341 - val_loss: 0.2957\n",
      "Epoch 6/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.2098 - val_loss: 0.2793\n",
      "Epoch 7/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.1884 - val_loss: 0.2642\n",
      "Epoch 8/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.1742 - val_loss: 0.2693\n",
      "Epoch 9/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.1531 - val_loss: 0.2570\n",
      "Epoch 10/10\n",
      "4136/4136 [==============================] - 3s - loss: 0.1390 - val_loss: 0.2499\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3899 - val_loss: 0.3665\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3205 - val_loss: 0.3412\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2907 - val_loss: 0.3251\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2603 - val_loss: 0.2999\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2331 - val_loss: 0.2923\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2102 - val_loss: 0.2722\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1889 - val_loss: 0.2678\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1679 - val_loss: 0.2537\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1496 - val_loss: 0.2542\n",
      "Epoch 10/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1361 - val_loss: 0.2574\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3839 - val_loss: 0.3660\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3170 - val_loss: 0.3410\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2901 - val_loss: 0.3176\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2586 - val_loss: 0.3029\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2329 - val_loss: 0.2900\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2084 - val_loss: 0.2720\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1864 - val_loss: 0.2710\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1683 - val_loss: 0.2681\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1507 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1368 - val_loss: 0.2522\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3873 - val_loss: 0.3710\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3217 - val_loss: 0.3440\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2939 - val_loss: 0.3221\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2634 - val_loss: 0.3034\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2391 - val_loss: 0.2965\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2142 - val_loss: 0.2805\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1925 - val_loss: 0.2630\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1729 - val_loss: 0.2652\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1551 - val_loss: 0.2588\n",
      "Epoch 10/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1437 - val_loss: 0.2530\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3805 - val_loss: 0.3686\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3244 - val_loss: 0.3485\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2925 - val_loss: 0.3216\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2647 - val_loss: 0.3090\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2369 - val_loss: 0.2970\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2146 - val_loss: 0.2835\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1912 - val_loss: 0.2710\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1735 - val_loss: 0.2654\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1582 - val_loss: 0.2568\n",
      "Epoch 10/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1405 - val_loss: 0.2649\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3813 - val_loss: 0.3656\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3200 - val_loss: 0.3415\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2902 - val_loss: 0.3180\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2610 - val_loss: 0.3007\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2342 - val_loss: 0.2846\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2114 - val_loss: 0.2782\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1870 - val_loss: 0.2699\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1691 - val_loss: 0.2582\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1550 - val_loss: 0.2532\n",
      "Epoch 10/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1395 - val_loss: 0.2616\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3819 - val_loss: 0.3685\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.3188 - val_loss: 0.3449\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2899 - val_loss: 0.3212\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2627 - val_loss: 0.3028\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2382 - val_loss: 0.2924\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.2138 - val_loss: 0.2785\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1921 - val_loss: 0.2669\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1721 - val_loss: 0.2591\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1530 - val_loss: 0.2570\n",
      "Epoch 10/10\n",
      "4137/4137 [==============================] - 3s - loss: 0.1393 - val_loss: 0.2596\n",
      "Train on 4138 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.3745 - val_loss: 0.3636\n",
      "Epoch 2/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.3179 - val_loss: 0.3386\n",
      "Epoch 3/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2887 - val_loss: 0.3210\n",
      "Epoch 4/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2587 - val_loss: 0.3016\n",
      "Epoch 5/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2313 - val_loss: 0.2894\n",
      "Epoch 6/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2129 - val_loss: 0.2763\n",
      "Epoch 7/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1902 - val_loss: 0.2760\n",
      "Epoch 8/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1755 - val_loss: 0.2682\n",
      "Epoch 9/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1578 - val_loss: 0.2589\n",
      "Epoch 10/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1405 - val_loss: 0.2611\n",
      "Train on 4138 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.3827 - val_loss: 0.3566\n",
      "Epoch 2/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.3202 - val_loss: 0.3321\n",
      "Epoch 3/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2871 - val_loss: 0.3183\n",
      "Epoch 4/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2582 - val_loss: 0.2897\n",
      "Epoch 5/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2296 - val_loss: 0.2766\n",
      "Epoch 6/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2080 - val_loss: 0.2701\n",
      "Epoch 7/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1847 - val_loss: 0.2519\n",
      "Epoch 8/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1663 - val_loss: 0.2507\n",
      "Epoch 9/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1503 - val_loss: 0.2392\n",
      "Epoch 10/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1322 - val_loss: 0.2424\n",
      "Train on 4138 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.3811 - val_loss: 0.4099\n",
      "Epoch 2/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.3181 - val_loss: 0.3810\n",
      "Epoch 3/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2858 - val_loss: 0.3604\n",
      "Epoch 4/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2527 - val_loss: 0.3475\n",
      "Epoch 5/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2235 - val_loss: 0.3501\n",
      "Epoch 6/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.2005 - val_loss: 0.3318\n",
      "Epoch 7/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1805 - val_loss: 0.3235\n",
      "Epoch 8/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1633 - val_loss: 0.3253\n",
      "Epoch 9/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1438 - val_loss: 0.3218\n",
      "Epoch 10/10\n",
      "4138/4138 [==============================] - 3s - loss: 0.1301 - val_loss: 0.3442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "auc          0.884428\n",
       "f1           0.507228\n",
       "precision    0.473284\n",
       "recall       0.568831\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequential model\n",
    "early_stopper = utils.MyEarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "scores = utils.seq_cross_validate(\n",
    "    utils.mk_yk_model_f(X.shape[1], my_embeddings, n_filters=300),\n",
    "    X, labels, \n",
    "    skf, eval_f=seq_eval_f,\n",
    "    fit_params={\n",
    "        \"callbacks\": [early_stopper],\n",
    "        \"validation_split\": .1,\n",
    "        \"batch_size\": 50\n",
    "    }, \n",
    "    verbose=0)\n",
    "df = pandas.DataFrame(scores)\n",
    "model_name = \"CNN\"\n",
    "df[\"model\"] = model_name\n",
    "results = pandas.concat([results[results[\"model\"] != model_name], df])\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'utils.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4136 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      " 950/4136 [=====>........................] - ETA: 9s - loss: 0.4740"
     ]
    }
   ],
   "source": [
    "# sequential model\n",
    "early_stopper = utils.MyEarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "scores = utils.seq_cross_validate(\n",
    "    utils.mk_gru_model_f(X.shape[1], my_embeddings),\n",
    "    X[:, ::-1], labels,\n",
    "    skf, eval_f=seq_eval_f,\n",
    "    verbose=0,\n",
    "    fit_params={\n",
    "        \"callbacks\": [early_stopper],\n",
    "        \"validation_split\": .1,\n",
    "        \"batch_size\": 50\n",
    "    })\n",
    "df = pandas.DataFrame(scores)\n",
    "model_name = \"GRU\"\n",
    "df[\"model\"] = model_name\n",
    "results = pandas.concat([results[results[\"model\"] != model_name], df])\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>0.587609</td>\n",
       "      <td>0.230405</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>0.892208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.884428</td>\n",
       "      <td>0.507228</td>\n",
       "      <td>0.473284</td>\n",
       "      <td>0.568831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNNA</th>\n",
       "      <td>0.868821</td>\n",
       "      <td>0.494731</td>\n",
       "      <td>0.403737</td>\n",
       "      <td>0.658636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRNN</th>\n",
       "      <td>0.869807</td>\n",
       "      <td>0.507763</td>\n",
       "      <td>0.489378</td>\n",
       "      <td>0.552922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0.867040</td>\n",
       "      <td>0.491331</td>\n",
       "      <td>0.492879</td>\n",
       "      <td>0.513571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-NBLCR</th>\n",
       "      <td>0.832942</td>\n",
       "      <td>0.233311</td>\n",
       "      <td>0.791053</td>\n",
       "      <td>0.139805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-TFIDF</th>\n",
       "      <td>0.854756</td>\n",
       "      <td>0.449863</td>\n",
       "      <td>0.331677</td>\n",
       "      <td>0.700260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-WE</th>\n",
       "      <td>0.823112</td>\n",
       "      <td>0.398744</td>\n",
       "      <td>0.274590</td>\n",
       "      <td>0.728734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCNN</th>\n",
       "      <td>0.867046</td>\n",
       "      <td>0.488006</td>\n",
       "      <td>0.433383</td>\n",
       "      <td>0.586851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               auc        f1  precision    recall\n",
       "model                                            \n",
       "CM        0.587609  0.230405   0.132295  0.892208\n",
       "CNN       0.884428  0.507228   0.473284  0.568831\n",
       "CNNA      0.868821  0.494731   0.403737  0.658636\n",
       "CRNN      0.869807  0.507763   0.489378  0.552922\n",
       "GRU       0.867040  0.491331   0.492879  0.513571\n",
       "ME-NBLCR  0.832942  0.233311   0.791053  0.139805\n",
       "ME-TFIDF  0.854756  0.449863   0.331677  0.700260\n",
       "ME-WE     0.823112  0.398744   0.274590  0.728734\n",
       "RCNN      0.867046  0.488006   0.433383  0.586851"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby('model').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4136 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.3502 - val_loss: 0.3575\n",
      "Epoch 2/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.2910 - val_loss: 0.3349\n",
      "Epoch 3/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.2588 - val_loss: 0.3876\n",
      "Epoch 4/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.2293 - val_loss: 0.2921\n",
      "Epoch 5/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.2104 - val_loss: 0.2950\n",
      "Epoch 6/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.1882 - val_loss: 0.2787\n",
      "Epoch 7/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.1578 - val_loss: 0.2682\n",
      "Epoch 8/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.1409 - val_loss: 0.2840\n",
      "Epoch 9/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.1238 - val_loss: 0.2873\n",
      "Epoch 10/10\n",
      "4136/4136 [==============================] - 8s - loss: 0.1041 - val_loss: 0.2865\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.3511 - val_loss: 0.3568\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2925 - val_loss: 0.3181\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2580 - val_loss: 0.2881\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2206 - val_loss: 0.2723\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1978 - val_loss: 0.2961\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1801 - val_loss: 0.2693\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1507 - val_loss: 0.2976\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1373 - val_loss: 0.2812\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1274 - val_loss: 0.2854\n",
      "Epoch 10/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.0949 - val_loss: 0.2910\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.3502 - val_loss: 0.3512\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2969 - val_loss: 0.3188\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2642 - val_loss: 0.3049\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2386 - val_loss: 0.2831\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2119 - val_loss: 0.3008\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1864 - val_loss: 0.2750\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1646 - val_loss: 0.2799\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1372 - val_loss: 0.2780\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1197 - val_loss: 0.3141\n",
      "Epoch 10/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1076 - val_loss: 0.3078\n",
      "Train on 4137 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.3487 - val_loss: 0.3432\n",
      "Epoch 2/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2956 - val_loss: 0.3244\n",
      "Epoch 3/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2624 - val_loss: 0.3007\n",
      "Epoch 4/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2294 - val_loss: 0.2865\n",
      "Epoch 5/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.2018 - val_loss: 0.3115\n",
      "Epoch 6/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1863 - val_loss: 0.3058\n",
      "Epoch 7/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1676 - val_loss: 0.2867\n",
      "Epoch 8/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1384 - val_loss: 0.3343\n",
      "Epoch 9/10\n",
      "4137/4137 [==============================] - 8s - loss: 0.1255 - val_loss: 0.3094"
     ]
    }
   ],
   "source": [
    "# sequential model\n",
    "early_stopper = utils.MyEarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "scores = utils.seq_cross_validate(\n",
    "    utils.mk_cgru_model_f(X.shape[1], my_embeddings, nb_filter=300, rnn_output=300),\n",
    "    X[:, ::-1], labels,\n",
    "    skf, eval_f=seq_eval_f,\n",
    "    verbose=0,\n",
    "    fit_params={\n",
    "        \"callbacks\": [early_stopper],\n",
    "        \"validation_split\": .1,\n",
    "        \"batch_size\": 50\n",
    "    })\n",
    "df = pandas.DataFrame(scores)\n",
    "model_name = \"CRNN\"\n",
    "df[\"model\"] = model_name\n",
    "results = pandas.concat([results[results[\"model\"] != model_name], df])\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopper = utils.MyEarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "scores = utils.seq_cross_validate(\n",
    "    utils.mk_rcnn_model_f(X.shape[1], my_embeddings, rnn_output=300, nb_filter=300, filter_length=5),\n",
    "    X, labels,\n",
    "    skf, eval_f=seq_eval_f,\n",
    "    verbose=0,\n",
    "    fit_params={\n",
    "        \"callbacks\": [early_stopper],\n",
    "        \"validation_split\": .1,\n",
    "        \"batch_size\": 50\n",
    "    })\n",
    "df = pandas.DataFrame(scores)\n",
    "model_name = \"RCNN\"\n",
    "df[\"model\"] = model_name\n",
    "results = pandas.concat([results[results[\"model\"] != model_name], df])\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>0.587609</td>\n",
       "      <td>0.230405</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>0.892208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.884428</td>\n",
       "      <td>0.507228</td>\n",
       "      <td>0.473284</td>\n",
       "      <td>0.568831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNNA</th>\n",
       "      <td>0.868821</td>\n",
       "      <td>0.494731</td>\n",
       "      <td>0.403737</td>\n",
       "      <td>0.658636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRNN</th>\n",
       "      <td>0.869807</td>\n",
       "      <td>0.507763</td>\n",
       "      <td>0.489378</td>\n",
       "      <td>0.552922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-NBLCR</th>\n",
       "      <td>0.832942</td>\n",
       "      <td>0.233311</td>\n",
       "      <td>0.791053</td>\n",
       "      <td>0.139805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-TFIDF</th>\n",
       "      <td>0.854756</td>\n",
       "      <td>0.449863</td>\n",
       "      <td>0.331677</td>\n",
       "      <td>0.700260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME-WE</th>\n",
       "      <td>0.823112</td>\n",
       "      <td>0.398744</td>\n",
       "      <td>0.274590</td>\n",
       "      <td>0.728734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCNN</th>\n",
       "      <td>0.867046</td>\n",
       "      <td>0.488006</td>\n",
       "      <td>0.433383</td>\n",
       "      <td>0.586851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               auc        f1  precision    recall\n",
       "model                                            \n",
       "CM        0.587609  0.230405   0.132295  0.892208\n",
       "CNN       0.884428  0.507228   0.473284  0.568831\n",
       "CNNA      0.868821  0.494731   0.403737  0.658636\n",
       "CRNN      0.869807  0.507763   0.489378  0.552922\n",
       "ME-NBLCR  0.832942  0.233311   0.791053  0.139805\n",
       "ME-TFIDF  0.854756  0.449863   0.331677  0.700260\n",
       "ME-WE     0.823112  0.398744   0.274590  0.728734\n",
       "RCNN      0.867046  0.488006   0.433383  0.586851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(\"model\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopper = utils.MyEarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "scores = utils.graph_cross_validate(\n",
    "    utils.mk_attention_based_model_f(X.shape[1], my_embeddings, attention_l2=0.1),\n",
    "    {\"tokens\": X, \"output\": labels},\n",
    "    skf,\n",
    "    eval_f=graph_eval_f,\n",
    "    verbose=0,\n",
    "    fit_params={\n",
    "        \"callbacks\": [early_stopper],\n",
    "        \"validation_split\": .1,\n",
    "        \"batch_size\": 50\n",
    "    })\n",
    "df = pandas.DataFrame(scores)\n",
    "model_name = \"CNNA\"\n",
    "df[\"model\"] = model_name\n",
    "results = pandas.concat([results[results[\"model\"] != model_name], df])\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4136 samples, validate on 460 samples\n",
      "Epoch 1/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.3568 - val_loss: 0.3665\n",
      "Epoch 2/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.3271 - val_loss: 0.3518\n",
      "Epoch 3/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.3080 - val_loss: 0.3645\n",
      "Epoch 4/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.2774 - val_loss: 0.3253\n",
      "Epoch 5/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.2396 - val_loss: 0.2738\n",
      "Epoch 6/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.2210 - val_loss: 0.2649\n",
      "Epoch 7/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.1835 - val_loss: 0.2548\n",
      "Epoch 8/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.1612 - val_loss: 0.3401\n",
      "Epoch 9/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.1328 - val_loss: 0.2801\n",
      "Epoch 10/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.1188 - val_loss: 0.2900\n",
      "Epoch 11/100\n",
      "4136/4136 [==============================] - 14s - loss: 0.0935 - val_loss: 0.3032\n",
      "Epoch 12/100\n",
      "4100/4136 [============================>.] - ETA: 0s - loss: 0.0839Epoch 00011: early stopping\n",
      "4136/4136 [==============================] - 14s - loss: 0.0836 - val_loss: 0.3594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10a978d490>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = utils.mk_attention_based_model_f(X.shape[1], my_embeddings)()\n",
    "early_stopper = utils.MyEarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "m.fit({\"tokens\": X[skf[0][0]], \"output\": labels[skf[0][0]]},\n",
    "      callbacks=[early_stopper],\n",
    "      batch_size=50,\n",
    "      validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "attentions = K.function([m.nodes[\"embedding\"].get_input()],\n",
    "                         [m.nodes[\"norm_attn_weights\"].get_output()])\n",
    "\n",
    "features = K.function([m.nodes[\"embedding\"].get_input()],\n",
    "                         [m.nodes[\"features\"].get_output()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"had\" in w2v.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tittuck i know it made me want to be sick every time i had it plus fluoxetine is the bigges bunch of shit ive been on worse than sertraline\n",
      "i know it made me want to be sick every time i had it plus fluoxetine is the bigges bunch of shit ive been on worse than sertraline\n",
      "[(u'i', 0.0056520808), (u'know', 0.013411545), (u'it', 0.028869804), (u'made', 0.036486648), (u'me', 0.042846639), (u'want', 0.047599487), (u'to', 0.071960993), (u'be', 0.095526487), (u'sick', 0.12615407), (u'every', 0.094749615), (u'time', 0.055059109), (u'i', 0.025319701), (u'had', 0.016237818), (u'it', 0.01196784), (u'plus', 0.010993169), (u'fluoxetine', 0.0097043943), (u'is', 0.0093425903), (u'the', 0.008333168), (u'bigges', 0.0076636323), (u'bunch', 0.0090183076), (u'of', 0.011944612), (u'shit', 0.019051364), (u'ive', 0.028213581), (u'been', 0.040556699), (u'on', 0.047379613), (u'worse', 0.049805731), (u'than', 0.036138404), (u'sertraline', 0.021764973)]\n",
      "\n",
      "@Shellyfanelly I was on #azathioprine for about 8 years, it worked well, now on #Humira instead though which is knocking me about\n",
      "i was on #azathioprine for about 8 years , it worked well , now on #humira instead though which is knocking me about\n",
      "[(u'i', 0.0040257093), (u'was', 0.0049896562), (u'on', 0.0052874847), (u'azathioprine', 0.005039419), (u'for', 0.0050331294), (u'about', 0.0058063571), (u'years', 0.0063013043), (u'it', 0.0077660675), (u'worked', 0.0091043049), (u'well', 0.0099929618), (u'now', 0.012303578), (u'on', 0.018139061), (u'humira', 0.028457157), (u'instead', 0.056304697), (u'though', 0.11440726), (u'which', 0.16794838), (u'is', 0.18819125), (u'knocking', 0.15654998), (u'me', 0.09365315), (u'about', 0.043975595)]\n",
      "\n",
      "I suggest never stop taking Effexor abruptly because you will feel like you're on your death bed\n",
      "i suggest never stop taking effexor abruptly because you will feel like you're on your death bed\n",
      "[(u'i', 0.0029096578), (u'suggest', 0.0061400607), (u'never', 0.01776276), (u'stop', 0.051025838), (u'taking', 0.11784347), (u'effexor', 0.15220515), (u'abruptly', 0.12874201), (u'because', 0.084542304), (u'you', 0.061322466), (u'will', 0.047600657), (u'feel', 0.041461762), (u'like', 0.029883888), (u'you', 0.020795401), (u're', 0.015637122), (u'on', 0.021162363), (u'your', 0.034465149), (u'death', 0.053443842), (u'bed', 0.04904836)]\n",
      "\n",
      "Trazodone is no joke. Slept through every alarm.\n",
      "trazodone is no joke . slept through every alarm .\n",
      "[(u'trazodone', 0.0077812229), (u'is', 0.02053625), (u'no', 0.060719442), (u'joke', 0.12994429), (u'slept', 0.21894781), (u'through', 0.21812706), (u'every', 0.15301348), (u'alarm', 0.067280121)]\n",
      "\n",
      "Sleeping my life away on #quetiapine. Fine by me.\n",
      "sleeping my life away on #quetiapine . fine by me .\n",
      "[(u'sleeping', 0.046111304), (u'my', 0.10329491), (u'life', 0.16700548), (u'away', 0.13931999), (u'on', 0.10308035), (u'quetiapine', 0.078096107), (u'fine', 0.069397666), (u'by', 0.058404636), (u'me', 0.045588888)]\n",
      "\n",
      "02.50 day 15 Rivaroxaban diary. Neck ache and lower back pain. Had to kneel on floor to get out of bed.\n",
      "02.50 day 15 rivaroxaban diary . neck ache and lower back pain . had to kneel on floor to get out of bed .\n",
      "[(u'day', 0.011913043), (u'rivaroxaban', 0.036956191), (u'diary', 0.090320989), (u'neck', 0.11009956), (u'ache', 0.10150408), (u'and', 0.072779924), (u'lower', 0.071563281), (u'back', 0.079605207), (u'pain', 0.086983502), (u'had', 0.07866396), (u'to', 0.060074031), (u'kneel', 0.036693912), (u'on', 0.022614999), (u'floor', 0.016092554), (u'to', 0.01451219), (u'get', 0.016110532), (u'out', 0.021644419), (u'of', 0.022129156), (u'bed', 0.018605057)]\n",
      "\n",
      "oh hello seroquel old friend I mi*passes out on bed*\n",
      "oh hello seroquel old friend i mi*passes out on bed *\n",
      "[(u'oh', 0.012495837), (u'hello', 0.016876945), (u'seroquel', 0.020407677), (u'old', 0.021521188), (u'friend', 0.023205396), (u'i', 0.027779043), (u'mi', 0.045106266), (u'passes', 0.08738485), (u'out', 0.15727343), (u'on', 0.19619268), (u'bed', 0.15252185)]\n",
      "\n",
      "My Effexor has left me with the inability to cry. I was dry eyed watching \"Into the Wild\" and even one of those Sarah Mclachlan commercials\n",
      "my effexor has left me with the inability to cry . i was dry eyed watching \" into the wild \" and even one of those sarah mclachlan commercials\n",
      "[(u'my', 0.011816852), (u'effexor', 0.025039887), (u'has', 0.034857444), (u'left', 0.034606215), (u'me', 0.030010523), (u'with', 0.033358227), (u'the', 0.039118689), (u'inability', 0.049054991), (u'to', 0.057634246), (u'cry', 0.071898788), (u'i', 0.084570952), (u'was', 0.11727464), (u'dry', 0.12549511), (u'eyed', 0.095274158), (u'watching', 0.051632632), (u'into', 0.027665315), (u'the', 0.014649979), (u'wild', 0.010292822), (u'and', 0.0084708529), (u'even', 0.0083179167), (u'one', 0.008323716), (u'of', 0.0084058437), (u'those', 0.0088949436), (u'sarah', 0.0086433552), (u'mclachlan', 0.0081424629), (u'commercials', 0.0068547307)]\n",
      "\n",
      "Since quetiapine's messed with my prolactin levels, making my boobs humungous & my bras so expensive, I want a lingerie component to DLA.\n",
      "since quetiapine's messed with my prolactin levels , making my boobs humungous & my bras so expensive , i want a lingerie component to dla .\n",
      "[(u'since', 0.010147216), (u'quetiapine', 0.017204612), (u's', 0.022897165), (u'messed', 0.025205938), (u'with', 0.026474033), (u'my', 0.033662502), (u'prolactin', 0.050716437), (u'levels', 0.089478254), (u'making', 0.13656549), (u'my', 0.1691978), (u'boobs', 0.14479959), (u'humungous', 0.08971858), (u'my', 0.046017807), (u'bras', 0.021686442), (u'so', 0.012882875), (u'expensive', 0.0085857268), (u'i', 0.006836981), (u'want', 0.0069206543), (u'a', 0.0081694229), (u'lingerie', 0.0092607327), (u'component', 0.011042915), (u'to', 0.011865701), (u'dla', 0.0090973256)]\n",
      "\n",
      "Just about dead, think it's bedtime.. Fuck you quetiapine\n",
      "just about dead , think it's bedtime .. fuck you quetiapine\n",
      "[(u'just', 0.017456124), (u'about', 0.040269371), (u'dead', 0.087963536), (u'think', 0.14225614), (u'it', 0.16040653), (u's', 0.12712629), (u'bedtime', 0.098620683), (u'fuck', 0.073725633), (u'you', 0.05644815), (u'quetiapine', 0.036542609)]\n",
      "\n",
      "@upasbook Great read as always. I was on Cymbalta for 5 days. Cold turkey had sweats, migraine, tremors while on & 3 days after.\n",
      "great read as always . i was on cymbalta for 5 days . cold turkey had sweats , migraine , tremors while on & 3 days after .\n",
      "[(u'great', 0.00086025888), (u'read', 0.0011240217), (u'as', 0.0015819893), (u'always', 0.0021496718), (u'i', 0.0023264633), (u'was', 0.0024185113), (u'on', 0.002597912), (u'cymbalta', 0.0034705698), (u'for', 0.0056260764), (u'days', 0.014651311), (u'cold', 0.03682632), (u'turkey', 0.099932723), (u'had', 0.1848779), (u'sweats', 0.25455534), (u'migraine', 0.18333583), (u'tremors', 0.099835433), (u'while', 0.045363754), (u'on', 0.023559954), (u'days', 0.012506818), (u'after', 0.0073574618)]\n",
      "\n",
      "Took a percocet for my tooth. Feel like I'm about to die cause of the Prozac thats already in my system. Apparently you can't take both. FML\n",
      "took a percocet for my tooth . feel like i'm about to die cause of the prozac thats already in my system . apparently you can't take both . fml\n",
      "[(u'took', 0.0090757385), (u'a', 0.013253142), (u'percocet', 0.022370115), (u'for', 0.038061962), (u'my', 0.077151343), (u'tooth', 0.1177095), (u'feel', 0.13371609), (u'like', 0.097647086), (u'i', 0.05683516), (u'm', 0.033753142), (u'about', 0.027545096), (u'to', 0.024909033), (u'die', 0.021625383), (u'cause', 0.016795119), (u'of', 0.012280101), (u'the', 0.010052132), (u'prozac', 0.0090646883), (u'thats', 0.0098837782), (u'already', 0.012734603), (u'in', 0.017682973), (u'my', 0.027379554), (u'system', 0.035443347), (u'apparently', 0.036550734), (u'you', 0.026355345), (u'ca', 0.018840704), (u'not', 0.014900258), (u'take', 0.016502643), (u'both', 0.018187298), (u'fml', 0.016620256)]\n",
      "\n",
      "ugh I wish my vyvanse didn't make my stomach hurt so bad\n",
      "ugh i wish my vyvanse didn't make my stomach hurt so bad\n",
      "[(u'ugh', 0.0034731661), (u'i', 0.0046223104), (u'wish', 0.006501304), (u'my', 0.0083801113), (u'vyvanse', 0.011529869), (u'did', 0.019638525), (u'not', 0.040230807), (u'make', 0.081152312), (u'my', 0.13945466), (u'stomach', 0.20411593), (u'hurt', 0.2074535), (u'so', 0.13889733), (u'bad', 0.066404402)]\n",
      "\n",
      "@OUCH_UK didnt know Lamotrigine was addictive Stopped as didnt think were helping @clusterheads 3 days of hell before realized, back on now\n",
      "didnt know lamotrigine was addictive stopped as didnt think were helping 3 days of hell before realized , back on now\n",
      "[(u'didnt', 0.011450403), (u'know', 0.030311998), (u'lamotrigine', 0.067278415), (u'was', 0.097795755), (u'addictive', 0.11828192), (u'stopped', 0.10427932), (u'as', 0.081640452), (u'didnt', 0.066612162), (u'think', 0.048188053), (u'were', 0.036296755), (u'helping', 0.027130809), (u'days', 0.025994062), (u'of', 0.025853952), (u'hell', 0.03416656), (u'before', 0.038418781), (u'realized', 0.046491805), (u'back', 0.042981535), (u'on', 0.034198966), (u'now', 0.019110195)]\n",
      "\n",
      "That nap was on point.... Cymbalta did that shit cuz I dont take naps...ever\n",
      "that nap was on point .... cymbalta did that shit cuz i dont take naps ... ever\n",
      "[(u'that', 0.026202342), (u'nap', 0.054688539), (u'was', 0.077515982), (u'on', 0.074523948), (u'point', 0.056517225), (u'cymbalta', 0.04344767), (u'did', 0.042007968), (u'that', 0.04487678), (u'shit', 0.039933845), (u'cuz', 0.032103401), (u'i', 0.027769959), (u'dont', 0.035265934), (u'take', 0.053332623), (u'naps', 0.085997202), (u'ever', 0.086157411)]\n",
      "\n",
      "venlafaxine makes me feel so nauseas hahahaha oh god I'm going to chunder in my geography lesson help\n",
      "venlafaxine makes me feel so nauseas hahahaha oh god i'm going to chunder in my geography lesson help\n",
      "[(u'venlafaxine', 0.029588167), (u'makes', 0.10870101), (u'me', 0.24783291), (u'feel', 0.26432613), (u'so', 0.16577546), (u'nauseas', 0.07606028), (u'hahahaha', 0.026703512), (u'oh', 0.01146935), (u'god', 0.0053293188), (u'i', 0.0039901696), (u'm', 0.0037466965), (u'going', 0.004632025), (u'to', 0.0049710372), (u'chunder', 0.0049763727), (u'in', 0.0040887916), (u'my', 0.0038453673), (u'geography', 0.0032172371), (u'lesson', 0.003421477), (u'help', 0.0032405283)]\n",
      "\n",
      "@LISABROWNPHOTOS Consider yourself lucky if all it does is make you dizzy and sick! Cipro crippled me and countless others.\n",
      "consider yourself lucky if all it does is make you dizzy and sick ! cipro crippled me and countless others .\n",
      "[(u'consider', 0.00073927443), (u'yourself', 0.0010026194), (u'lucky', 0.0013292134), (u'if', 0.001613514), (u'all', 0.0023716993), (u'it', 0.0039252141), (u'does', 0.0093350522), (u'is', 0.018933702), (u'make', 0.048377629), (u'you', 0.081585139), (u'dizzy', 0.15222615), (u'and', 0.19251564), (u'sick', 0.23098293), (u'cipro', 0.13722757), (u'crippled', 0.064663522), (u'me', 0.024884352), (u'and', 0.010452268), (u'countless', 0.0051576085), (u'others', 0.0031511944)]\n",
      "\n",
      "\"@vyvanseswag: I run on Vyvanse and RedBull.\" So done with that life. Vyvance cooked my brain like a stove top\n",
      "\" : i run on vyvanse and redbull . \" so done with that life . vyvance cooked my brain like a stove top\n",
      "[(u'i', 0.0074476567), (u'run', 0.012922715), (u'on', 0.018498998), (u'vyvanse', 0.021159809), (u'and', 0.018777331), (u'redbull', 0.015430998), (u'so', 0.011659602), (u'done', 0.012171113), (u'with', 0.016422274), (u'that', 0.026745236), (u'life', 0.049729828), (u'vyvance', 0.074477419), (u'cooked', 0.10509805), (u'my', 0.12711592), (u'brain', 0.12148391), (u'like', 0.11112017), (u'a', 0.089260481), (u'stove', 0.057542972), (u'top', 0.031167842)]\n",
      "\n",
      "@secretsufferer Olanzapine. I was taking 7.5mg and that was a nightmare, now taking 5mg but the weight still keeps coming :(\n",
      "olanzapine . i was taking 7.5 mg and that was a nightmare , now taking 5mg but the weight still keeps coming :(\n",
      "[(u'olanzapine', 0.0056035607), (u'i', 0.0068918052), (u'was', 0.0070054457), (u'taking', 0.0054490976), (u'mg', 0.0043593775), (u'and', 0.0056348094), (u'that', 0.0092165256), (u'was', 0.018963816), (u'a', 0.028126484), (u'nightmare', 0.0304671), (u'now', 0.018763393), (u'taking', 0.015081808), (u'mg', 0.012263875), (u'but', 0.021707283), (u'the', 0.046885144), (u'weight', 0.12517732), (u'still', 0.20649275), (u'keeps', 0.22946835), (u'coming', 0.11921772)]\n",
      "\n",
      "Question time #crohns #ibd #humira does anyone suffer from egg burps? What works for you\n",
      "question time crohns ibd #humira does anyone suffer from egg burps ? what works for you\n",
      "[(u'question', 0.010376257), (u'time', 0.013520205), (u'crohns', 0.014248464), (u'ibd', 0.014879517), (u'humira', 0.022841372), (u'does', 0.050394278), (u'anyone', 0.13322611), (u'suffer', 0.24547781), (u'from', 0.21276015), (u'egg', 0.097532265), (u'burps', 0.03381614), (u'what', 0.014853563), (u'works', 0.010841883), (u'for', 0.011397499), (u'you', 0.012633266)]\n",
      "\n",
      "@cheer_bear13 @LithiumLibGirl I couldn't take lamictal 1 week into it I got the rash.a rush trip to the ER.6 months till rash was gone.\n",
      "i couldn't take lamictal 1 week into it i got the rash . a rush trip to the er . 6 months till rash was gone .\n",
      "[(u'i', 0.005504299), (u'could', 0.0067947218), (u'not', 0.0079379175), (u'take', 0.0077317948), (u'lamictal', 0.0077006803), (u'week', 0.0085074911), (u'into', 0.0098519847), (u'it', 0.012629961), (u'i', 0.01528972), (u'got', 0.026337454), (u'the', 0.03886329), (u'rash', 0.059597719), (u'a', 0.057383914), (u'rush', 0.051758077), (u'trip', 0.034807522), (u'to', 0.033248372), (u'the', 0.04003232), (u'er', 0.056796741), (u'months', 0.085485063), (u'till', 0.11413024), (u'rash', 0.12094613), (u'was', 0.087379351), (u'gone', 0.052636709)]\n",
      "\n",
      "Woke up to breakfast in bed...well couch because I'm addicted to the new 3D wifi tv. Too bad I have no appetite. Thanks Cymbalta.\n",
      "woke up to breakfast in bed ... well couch because i'm addicted to the new 3d wifi tv . too bad i have no appetite . thanks cymbalta .\n",
      "[(u'woke', 0.031467479), (u'up', 0.061744731), (u'to', 0.072465256), (u'breakfast', 0.05364807), (u'in', 0.038777754), (u'bed', 0.038516421), (u'well', 0.034001362), (u'couch', 0.043032873), (u'because', 0.042747341), (u'i', 0.043004323), (u'm', 0.030705567), (u'addicted', 0.021365136), (u'to', 0.012515469), (u'the', 0.0081515405), (u'new', 0.005802847), (u'd', 0.0058727409), (u'wifi', 0.0075862892), (u'tv', 0.011553557), (u'too', 0.01745072), (u'bad', 0.027799414), (u'i', 0.037438989), (u'have', 0.054875784), (u'no', 0.076260716), (u'appetite', 0.088702127), (u'thanks', 0.063980393), (u'cymbalta', 0.036262304)]\n",
      "\n",
      "Brisdelle dangerous. Paxil is supposed to treat depression and suicidal thoughts. I took Paxil and got depressed. Went off & OK in 2 wk.\n",
      "brisdelle dangerous . paxil is supposed to treat depression and suicidal thoughts . i took paxil and got depressed . went off & ok in 2 wk .\n",
      "[(u'dangerous', 0.019035947), (u'paxil', 0.036520075), (u'is', 0.055863522), (u'supposed', 0.05479306), (u'to', 0.053482734), (u'treat', 0.055410538), (u'depression', 0.068177372), (u'and', 0.085393533), (u'suicidal', 0.10161822), (u'thoughts', 0.074032754), (u'i', 0.042827178), (u'took', 0.027151182), (u'paxil', 0.021781873), (u'and', 0.023814349), (u'got', 0.033133239), (u'depressed', 0.041152384), (u'went', 0.039099593), (u'off', 0.032878645), (u'ok', 0.025519572), (u'in', 0.019102814), (u'wk', 0.015036761)]\n",
      "\n",
      "@MondaysMomma It's ok, I guess it's just a case of trial and error with antidepressants. Coming off venlafaxine has been so nasty :(\n",
      "it's ok , i guess it's just a case of trial and error with antidepressants . coming off venlafaxine has been so nasty :(\n",
      "[(u'it', 0.0045374297), (u's', 0.0054273079), (u'ok', 0.0063696234), (u'i', 0.0062771928), (u'guess', 0.0074775061), (u'it', 0.0081115793), (u's', 0.008727286), (u'just', 0.0082855858), (u'a', 0.0075699892), (u'case', 0.0065188142), (u'of', 0.0059090285), (u'trial', 0.0064658131), (u'and', 0.0078151692), (u'error', 0.013129689), (u'with', 0.027758941), (u'antidepressants', 0.054751825), (u'coming', 0.091910005), (u'off', 0.10298257), (u'venlafaxine', 0.10876765), (u'has', 0.10670464), (u'been', 0.12900037), (u'so', 0.11395517), (u'nasty', 0.08309602)]\n",
      "\n",
      "All I have to say is Cipro will mess you up kids. Don't get sick! #blagh #gross #weak\n",
      "all i have to say is cipro will mess you up kids . don't get sick ! blagh gross weak\n",
      "[(u'all', 0.0035351117), (u'i', 0.0045995335), (u'have', 0.0065802676), (u'to', 0.0085011749), (u'say', 0.013329378), (u'is', 0.021044753), (u'cipro', 0.035075966), (u'will', 0.042983487), (u'mess', 0.047101408), (u'you', 0.033837937), (u'up', 0.022292227), (u'kids', 0.018455472), (u'do', 0.02400298), (u'not', 0.046186868), (u'get', 0.0984319), (u'sick', 0.18323138), (u'blagh', 0.18347232), (u'gross', 0.11297756), (u'weak', 0.044729948)]\n",
      "\n",
      "@foggymelon @movmctov @The_Scottymomma when I did Humira for my Crohn's it felt like acid, hubby had to shoot me up. Made my lupus flare too\n",
      "when i did humira for my crohn's it felt like acid , hubby had to shoot me up . made my lupus flare too\n",
      "[(u'when', 0.0026547529), (u'i', 0.0029993991), (u'did', 0.0034771818), (u'humira', 0.0037229054), (u'for', 0.0041484674), (u'my', 0.0055083507), (u'crohn', 0.0074921614), (u's', 0.012608745), (u'it', 0.023989288), (u'felt', 0.042020984), (u'like', 0.058494579), (u'acid', 0.062249787), (u'hubby', 0.056892749), (u'had', 0.050762028), (u'to', 0.054076243), (u'shoot', 0.058684547), (u'me', 0.069685191), (u'up', 0.080246195), (u'made', 0.089081794), (u'my', 0.095792085), (u'lupus', 0.084632196), (u'flare', 0.060054049), (u'too', 0.033151466)]\n",
      "\n",
      "21.19 day 17 Rivaroxaban diary. Aches are related to pressure on my body, e.g. If sitting then in back, buttoocks and legs 1/2\n",
      "21.19 day 17 rivaroxaban diary . aches are related to pressure on my body , e.g. if sitting then in back , buttoocks and legs 1/2\n",
      "[(u'day', 0.021311795), (u'rivaroxaban', 0.055156242), (u'diary', 0.10556072), (u'aches', 0.12891077), (u'are', 0.10248329), (u'related', 0.076482005), (u'to', 0.064863466), (u'pressure', 0.056934413), (u'on', 0.04574446), (u'my', 0.030081293), (u'body', 0.017390408), (u'e', 0.0089058913), (u'g', 0.0062131505), (u'if', 0.0058115055), (u'sitting', 0.0072366362), (u'then', 0.012727388), (u'in', 0.023094634), (u'back', 0.04488356), (u'and', 0.055932272), (u'legs', 0.054551113)]\n",
      "\n",
      "Gotta find an alternative to Vyvanse, ASAP. I'd rather be sleepy & happy, than alert & depressed!\n",
      "gotta find an alternative to vyvanse , asap . i'd rather be sleepy & happy , than alert & depressed !\n",
      "[(u'gotta', 0.0053046201), (u'find', 0.0083263842), (u'an', 0.012483821), (u'alternative', 0.016226389), (u'to', 0.017533807), (u'vyvanse', 0.0150869), (u'asap', 0.01066954), (u'i', 0.011453837), (u'd', 0.014962066), (u'rather', 0.030920979), (u'be', 0.061185189), (u'sleepy', 0.12617262), (u'happy', 0.16845524), (u'than', 0.19029458), (u'alert', 0.13166243), (u'depressed', 0.07521034)]\n",
      "\n",
      "@theJeremyVine I once had an allergic reaction to the anti-convulsant Lamotrigine. I got a rash all over my body that looked like burns.\n",
      "i once had an allergic reaction to the anti-convulsant lamotrigine . i got a rash all over my body that looked like burns .\n",
      "[(u'i', 0.0053010294), (u'once', 0.01603654), (u'had', 0.05832262), (u'an', 0.12824795), (u'allergic', 0.18461603), (u'reaction', 0.11996775), (u'to', 0.062371083), (u'the', 0.025877032), (u'anti', 0.01246455), (u'convulsant', 0.0072503039), (u'lamotrigine', 0.0073063136), (u'i', 0.0089918477), (u'got', 0.015656905), (u'a', 0.025127217), (u'rash', 0.036322698), (u'all', 0.034463327), (u'over', 0.031150237), (u'my', 0.022982024), (u'body', 0.023371581), (u'that', 0.026725736), (u'looked', 0.035949476), (u'like', 0.040066145), (u'burns', 0.031576321)]\n",
      "\n",
      "\"@vyvanseswag: I don't know whether my Vyvanse caused my caffeine addiction or caffeine caused my Vyvanse addiction.\" OMG SO TRUE!! Ahh!\n",
      "\" : i don't know whether my vyvanse caused my caffeine addiction or caffeine caused my vyvanse addiction . \" omg so true !! ahh !\n",
      "[(u'i', 0.00060595077), (u'do', 0.00091851107), (u'not', 0.0015834551), (u'know', 0.003661003), (u'whether', 0.0084568737), (u'my', 0.020265527), (u'vyvanse', 0.041781396), (u'caused', 0.069641113), (u'my', 0.083528049), (u'caffeine', 0.10348722), (u'addiction', 0.11008475), (u'or', 0.10336506), (u'caffeine', 0.10380706), (u'caused', 0.10651622), (u'my', 0.089018859), (u'vyvanse', 0.061915848), (u'addiction', 0.039364036), (u'omg', 0.020521689), (u'so', 0.011733348), (u'true', 0.0069722184), (u'ahh', 0.0041491343)]\n",
      "\n",
      "@southkirk @PositiveAboutMS Thinking it might be the baclofen doing it.Only on a low dose though.Broken sleep is a nightmare.#MSFatigue\n",
      "thinking it might be the baclofen doing it . only on a low dose though . broken sleep is a nightmare . msfatigue\n",
      "[(u'thinking', 0.0021739849), (u'it', 0.0036304099), (u'might', 0.0051444187), (u'be', 0.0059275962), (u'the', 0.0063626938), (u'baclofen', 0.0071810046), (u'doing', 0.010778064), (u'it', 0.017769087), (u'only', 0.024685001), (u'on', 0.031334333), (u'a', 0.037567917), (u'low', 0.048482928), (u'dose', 0.067494586), (u'though', 0.1026139), (u'broken', 0.13658929), (u'sleep', 0.16692297), (u'is', 0.1478252), (u'a', 0.099645317), (u'nightmare', 0.044039007)]\n",
      "\n",
      "For anxiety to penetrate through my drowsy haze (a result of the triumvirate of fluoxetine, pregabalin, amoxicillin?) is pretty good going.\n",
      "for anxiety to penetrate through my drowsy haze ( a result of the triumvirate of fluoxetine , pregabalin , amoxicillin ? ) is pretty good going .\n",
      "[(u'for', 0.0061673326), (u'anxiety', 0.013403947), (u'to', 0.02868714), (u'penetrate', 0.058388498), (u'through', 0.10397533), (u'my', 0.18718824), (u'drowsy', 0.23546901), (u'haze', 0.16896613), (u'a', 0.077774465), (u'result', 0.027390841), (u'of', 0.011215577), (u'the', 0.0062635946), (u'triumvirate', 0.0046666288), (u'of', 0.0042920592), (u'fluoxetine', 0.0050569712), (u'pregabalin', 0.0055112448), (u'amoxicillin', 0.0060711191), (u'is', 0.0060866517), (u'pretty', 0.0062531633), (u'good', 0.0057437592), (u'going', 0.0056274482)]\n",
      "\n",
      "@Wee_Jendo Nicotine lozenges. If I go cold turkey I can't think (or see) straight, so I can't work.\n",
      "nicotine lozenges . if i go cold turkey i can't think ( or see ) straight , so i can't work .\n",
      "[(u'nicotine', 0.0083895279), (u'lozenges', 0.011049679), (u'if', 0.017063648), (u'i', 0.03108746), (u'go', 0.059255783), (u'cold', 0.089266039), (u'turkey', 0.096687891), (u'i', 0.07457222), (u'ca', 0.059480552), (u'not', 0.050536804), (u'think', 0.057950456), (u'or', 0.059848823), (u'see', 0.056539934), (u'straight', 0.043816321), (u'so', 0.031537391), (u'i', 0.024548143), (u'ca', 0.024886742), (u'not', 0.027164651), (u'work', 0.027517645)]\n",
      "\n",
      "What to do? Not looking forward to cold turkey withdrawals from Pristiq... sense of impending doom. Anxiety only makes the situation worse.\n",
      "what to do ? not looking forward to cold turkey withdrawals from pristiq ... sense of impending doom . anxiety only makes the situation worse .\n",
      "[(u'what', 0.0011361563), (u'to', 0.0015745088), (u'do', 0.0022909248), (u'not', 0.0035577957), (u'looking', 0.0060896468), (u'forward', 0.014978935), (u'to', 0.040038694), (u'cold', 0.095694147), (u'turkey', 0.13953052), (u'withdrawals', 0.12329657), (u'from', 0.063221924), (u'pristiq', 0.03338366), (u'sense', 0.023638166), (u'of', 0.021067729), (u'impending', 0.02741052), (u'doom', 0.036142707), (u'anxiety', 0.048432883), (u'only', 0.053859536), (u'makes', 0.075601146), (u'the', 0.072064869), (u'situation', 0.059420142), (u'worse', 0.031326432)]\n",
      "\n",
      "I couldn't remember if I took a vyvanse or not early so I took another one &now I'm spazzing out... bc obviously I took one already #adhd\n",
      "i couldn't remember if i took a vyvanse or not early so i took another one & now i'm spazzing out ... bc obviously i took one already adhd\n",
      "[(u'i', 0.016773233), (u'could', 0.025101939), (u'not', 0.027822543), (u'remember', 0.027365955), (u'if', 0.024690108), (u'i', 0.023896625), (u'took', 0.026023312), (u'a', 0.030675191), (u'vyvanse', 0.032692667), (u'or', 0.033474777), (u'not', 0.033032879), (u'early', 0.027498979), (u'so', 0.023743544), (u'i', 0.019051885), (u'took', 0.017279962), (u'another', 0.018087419), (u'one', 0.023299851), (u'now', 0.029028703), (u'i', 0.038676381), (u'm', 0.0450445), (u'spazzing', 0.054750815), (u'out', 0.055573229), (u'bc', 0.050545391), (u'obviously', 0.040509753), (u'i', 0.032171834), (u'took', 0.033043716), (u'one', 0.042456906), (u'already', 0.052509591), (u'adhd', 0.042910084)]\n",
      "\n",
      "@jessicama20045 You know that Cipro is also made by Bayer, right? And it ALSO causes a horrific syndrome that mimics an auto-immune disease.\n",
      "you know that cipro is also made by bayer , right ? and it also causes a horrific syndrome that mimics an auto-immune disease .\n",
      "[(u'you', 0.002669628), (u'know', 0.0055031371), (u'that', 0.010407278), (u'cipro', 0.016669769), (u'is', 0.019345779), (u'also', 0.021146867), (u'made', 0.016653888), (u'by', 0.011228097), (u'bayer', 0.0073433421), (u'right', 0.0077093625), (u'and', 0.010376552), (u'it', 0.024872303), (u'also', 0.071917839), (u'causes', 0.16086102), (u'a', 0.21164599), (u'horrific', 0.17574471), (u'syndrome', 0.089203969), (u'that', 0.039780021), (u'mimics', 0.022836054), (u'an', 0.01650941), (u'auto', 0.015307081), (u'immune', 0.014112794), (u'disease', 0.010245739)]\n",
      "\n",
      "Maybe cos of the insulin blocking effect of seroquel but I do feel sugar crashes when eat fast carbs. Will feel ill. So avoid where poss.\n",
      "maybe cos of the insulin blocking effect of seroquel but i do feel sugar crashes when eat fast carbs . will feel ill . so avoid where poss .\n",
      "[(u'maybe', 0.0028777244), (u'cos', 0.0041899821), (u'of', 0.0066275606), (u'the', 0.0089165596), (u'insulin', 0.01153357), (u'blocking', 0.011816333), (u'effect', 0.011814203), (u'of', 0.0081929667), (u'seroquel', 0.0066333986), (u'but', 0.0065575307), (u'i', 0.010360445), (u'do', 0.019833406), (u'feel', 0.052737068), (u'sugar', 0.097878352), (u'crashes', 0.15018342), (u'when', 0.14500217), (u'eat', 0.12379538), (u'fast', 0.075962842), (u'carbs', 0.058235295), (u'will', 0.045304924), (u'feel', 0.040125698), (u'ill', 0.028871601), (u'so', 0.023225207), (u'avoid', 0.017457232), (u'where', 0.011762939), (u'poss', 0.0073673986)]\n",
      "\n",
      "@NeelieB @DavidJuurlink @US_FDA hot flashes won't be around forever; but weaning of paroxetine could be a nightmare\n",
      "hot flashes won't be around forever ; but weaning of paroxetine could be a nightmare\n",
      "[(u'hot', 0.010617591), (u'flashes', 0.01522284), (u'wo', 0.018865475), (u'not', 0.017637054), (u'be', 0.018653285), (u'around', 0.019541688), (u'forever', 0.022243978), (u'but', 0.02420203), (u'weaning', 0.027408451), (u'of', 0.031978685), (u'paroxetine', 0.05156213), (u'could', 0.099478938), (u'be', 0.17912167), (u'a', 0.2036249), (u'nightmare', 0.13326447)]\n",
      "\n",
      "Wondered why my limbs ached and I was shivering on the hottest day of the year so far. Forgot my venlafaxine. That'll be withdrawal then!\n",
      "wondered why my limbs ached and i was shivering on the hottest day of the year so far . forgot my venlafaxine . that'll be withdrawal then !\n",
      "[(u'wondered', 0.016873166), (u'why', 0.046603374), (u'my', 0.09567862), (u'limbs', 0.091063485), (u'ached', 0.071095482), (u'and', 0.042540509), (u'i', 0.033290345), (u'was', 0.029202698), (u'shivering', 0.028443485), (u'on', 0.024055999), (u'the', 0.018347317), (u'hottest', 0.011616241), (u'day', 0.0082104914), (u'of', 0.0068004387), (u'the', 0.006518784), (u'year', 0.0066607548), (u'so', 0.0093380334), (u'far', 0.011593672), (u'forgot', 0.014422746), (u'my', 0.013681119), (u'venlafaxine', 0.016801219), (u'that', 0.019570131), (u'll', 0.038031865), (u'be', 0.068806611), (u'withdrawal', 0.11399698), (u'then', 0.087437153)]\n",
      "\n",
      "@fibrofighter08 Venlafaxine gave me horrendous nightmares, & coming of it was horrific.!\n",
      "venlafaxine gave me horrendous nightmares , & coming of it was horrific .!\n",
      "[(u'venlafaxine', 0.01582328), (u'gave', 0.061102625), (u'me', 0.17724329), (u'horrendous', 0.22217566), (u'nightmares', 0.16506319), (u'coming', 0.10396498), (u'of', 0.068017215), (u'it', 0.058481626), (u'was', 0.04736948), (u'horrific', 0.033529639)]\n",
      "\n",
      "My battle continues with Olanzapine weight gain with a bowl of porridge and a 9am bootcamp #iwillwin\n",
      "my battle continues with olanzapine weight gain with a bowl of porridge and a 9am bootcamp iwillwin\n",
      "[(u'my', 0.010069733), (u'battle', 0.025264865), (u'continues', 0.067545377), (u'with', 0.11556067), (u'olanzapine', 0.17032582), (u'weight', 0.17736492), (u'gain', 0.12658195), (u'with', 0.070475392), (u'a', 0.036750458), (u'bowl', 0.021766117), (u'of', 0.016387451), (u'porridge', 0.016242435), (u'and', 0.019360624), (u'a', 0.025435871), (u'am', 0.024837369), (u'bootcamp', 0.019006891)]\n",
      "\n",
      "Seriously if you are getting off cymbalta tape alot if movies I was up till 4 and feel and look like a zombie just to tired to growl !!!\n",
      "seriously if you are getting off cymbalta tape alot if movies i was up till 4 and feel and look like a zombie just to tired to growl !!!\n",
      "[(u'seriously', 0.0020869689), (u'if', 0.0033727875), (u'you', 0.0058130776), (u'are', 0.007420525), (u'getting', 0.009541559), (u'off', 0.0089159179), (u'cymbalta', 0.0073727146), (u'tape', 0.004887376), (u'alot', 0.0038233157), (u'if', 0.0031652525), (u'movies', 0.0035726905), (u'i', 0.0042778263), (u'was', 0.0063734492), (u'up', 0.0085264714), (u'till', 0.010158409), (u'and', 0.0098836189), (u'feel', 0.011561465), (u'and', 0.015169629), (u'look', 0.022923971), (u'like', 0.037331153), (u'a', 0.062943175), (u'zombie', 0.090720274), (u'just', 0.12890044), (u'to', 0.16884914), (u'tired', 0.17580222), (u'to', 0.11336122), (u'growl', 0.049443271)]\n",
      "\n",
      "@weswroten @bullfrogr wow Paxil sent me into a huge hypo manic mixed episode.\n",
      "wow paxil sent me into a huge hypo manic mixed episode .\n",
      "[(u'wow', 0.0056979996), (u'paxil', 0.011430498), (u'sent', 0.021271968), (u'me', 0.041309331), (u'into', 0.073297516), (u'a', 0.11828252), (u'huge', 0.15603536), (u'hypo', 0.1810198), (u'manic', 0.15623437), (u'mixed', 0.10390357), (u'episode', 0.051132355)]\n",
      "\n",
      "@Nichole_Lindsey I've had Cipro before. Luckily for me, the only side fx I tend to get from AB is gastic upset. But I RARELY use AB.\n",
      "i've had cipro before . luckily for me , the only side fx i tend to get from ab is gastic upset . but i rarely use ab .\n",
      "[(u'i', 0.0094509162), (u've', 0.020299831), (u'had', 0.036276836), (u'cipro', 0.052917589), (u'before', 0.051137477), (u'luckily', 0.045019161), (u'for', 0.03406816), (u'me', 0.040376429), (u'the', 0.048944797), (u'only', 0.069484688), (u'side', 0.076918088), (u'fx', 0.062210858), (u'i', 0.041257013), (u'tend', 0.033901431), (u'to', 0.028878255), (u'get', 0.030067071), (u'from', 0.036134131), (u'ab', 0.041507944), (u'is', 0.042035088), (u'gastic', 0.041397639), (u'upset', 0.033433728), (u'but', 0.02500399), (u'i', 0.018748114), (u'rarely', 0.017198715), (u'use', 0.015671143), (u'ab', 0.013609562)]\n",
      "\n",
      "Off to see the gi consultant this week. Hope theres something other than humira to try as not working also hair falling out.\n",
      "off to see the gi consultant this week . hope theres something other than humira to try as not working also hair falling out .\n",
      "[(u'off', 0.0067941924), (u'to', 0.0084945709), (u'see', 0.0098200245), (u'the', 0.0080405744), (u'gi', 0.0060382891), (u'consultant', 0.0046037445), (u'this', 0.0045071738), (u'week', 0.0051027015), (u'hope', 0.0064490759), (u'theres', 0.008580097), (u'something', 0.011023992), (u'other', 0.01231739), (u'than', 0.012088408), (u'humira', 0.010662777), (u'to', 0.0096099069), (u'try', 0.0089571811), (u'as', 0.010790169), (u'not', 0.019127691), (u'working', 0.048894491), (u'also', 0.13229898), (u'hair', 0.23323643), (u'falling', 0.22866474), (u'out', 0.11499216)]\n",
      "\n",
      "@whatkatie_did I'm certainly weird but it's quetiapine instead of crack, I can't get that on prescription.\n",
      "i'm certainly weird but it's quetiapine instead of crack , i can't get that on prescription .\n",
      "[(u'i', 0.020642312), (u'm', 0.042495467), (u'certainly', 0.082567714), (u'weird', 0.111349), (u'but', 0.10910667), (u'it', 0.089314133), (u's', 0.064591914), (u'quetiapine', 0.049783979), (u'instead', 0.046244171), (u'of', 0.040625993), (u'crack', 0.029299302), (u'i', 0.020974649), (u'ca', 0.017853957), (u'not', 0.016409157), (u'get', 0.021685421), (u'that', 0.02912453), (u'on', 0.037993722), (u'prescription', 0.032761581)]\n",
      "\n",
      "My choice was more #surgery on 6-ft small bowel or #Biologics like #Humira. Now #chemo is my only hope 2 treat #lung side effect. #Crohns\n",
      "my choice was more #surgery on 6-ft small bowel or #biologics like #humira . now #chemo is my only hope 2 treat #lung side effect . crohns\n",
      "[(u'my', 0.0049513713), (u'choice', 0.0078935558), (u'was', 0.014055955), (u'more', 0.019284887), (u'surgery', 0.027566366), (u'on', 0.026858686), (u'ft', 0.025253274), (u'small', 0.019429432), (u'bowel', 0.016771914), (u'or', 0.012650596), (u'biologics', 0.012167528), (u'like', 0.012550381), (u'humira', 0.014702162), (u'now', 0.017429965), (u'chemo', 0.020300785), (u'is', 0.020540792), (u'my', 0.022399357), (u'only', 0.027433032), (u'hope', 0.042504556), (u'treat', 0.074822664), (u'lung', 0.12542412), (u'side', 0.17338122), (u'effect', 0.14381146), (u'crohns', 0.066407524)]\n",
      "\n",
      "@ctr1945 my mom used Rivaroxaban and it gave her a terrible time with weakness and muscle pain.\n",
      "my mom used rivaroxaban and it gave her a terrible time with weakness and muscle pain .\n",
      "[(u'my', 0.0019431454), (u'mom', 0.0023572273), (u'used', 0.0028842934), (u'rivaroxaban', 0.0038699831), (u'and', 0.0062631289), (u'it', 0.012576772), (u'gave', 0.020946221), (u'her', 0.030181196), (u'a', 0.037935708), (u'terrible', 0.037235256), (u'time', 0.048251621), (u'with', 0.07219623), (u'weakness', 0.13703945), (u'and', 0.1895927), (u'muscle', 0.21512964), (u'pain', 0.10729454)]\n",
      "\n",
      "@JessBarrett227 Taking someone off 150mg off Seroquel, mixing it with Olanzapine in 2 wks causes psychosis - a proper assess was not done.\n",
      "taking someone off 150mg off seroquel , mixing it with olanzapine in 2 wks causes psychosis - a proper assess was not done .\n",
      "[(u'taking', 0.01001263), (u'someone', 0.01374002), (u'off', 0.017995888), (u'mg', 0.016374532), (u'off', 0.01840258), (u'seroquel', 0.021996163), (u'mixing', 0.02809548), (u'it', 0.037133288), (u'with', 0.044664204), (u'olanzapine', 0.063417971), (u'in', 0.0836621), (u'wks', 0.1331076), (u'causes', 0.14267886), (u'psychosis', 0.12717454), (u'a', 0.071185999), (u'proper', 0.038105477), (u'assess', 0.021380492), (u'was', 0.017034914), (u'not', 0.016306058), (u'done', 0.01543224)]\n",
      "\n",
      "So apparently 60mgs of Prozac will make you scared of eating GMO's and make you think you need to save the world! Switching back to 40mgs!!!\n",
      "so apparently 60mgs of prozac will make you scared of eating gmo's and make you think you need to save the world ! switching back to 40mgs !!!\n",
      "[(u'so', 0.010484179), (u'apparently', 0.011727639), (u'mgs', 0.011351586), (u'of', 0.0096270656), (u'prozac', 0.012074618), (u'will', 0.020235335), (u'make', 0.048958469), (u'you', 0.083460823), (u'scared', 0.10280405), (u'of', 0.069207326), (u'eating', 0.039981145), (u'gmo', 0.019817503), (u's', 0.01670103), (u'and', 0.018917901), (u'make', 0.030049877), (u'you', 0.037922733), (u'think', 0.040131792), (u'you', 0.029283743), (u'need', 0.020260606), (u'to', 0.016437275), (u'save', 0.019792719), (u'the', 0.028754249), (u'world', 0.044459131), (u'switching', 0.058658697), (u'back', 0.068960086), (u'to', 0.056688767), (u'mgs', 0.035160188)]\n",
      "\n",
      "@mikedelic if this is a real question, withdrawal from an antidepressant named Effexor was worse than cocaine withdrawal\n",
      "if this is a real question , withdrawal from an antidepressant named effexor was worse than cocaine withdrawal\n",
      "[(u'if', 0.0016127598), (u'this', 0.0025196429), (u'is', 0.0053264098), (u'a', 0.012045891), (u'real', 0.026787199), (u'question', 0.047636963), (u'withdrawal', 0.062905051), (u'from', 0.056359302), (u'an', 0.043818351), (u'antidepressant', 0.039156072), (u'named', 0.034646221), (u'effexor', 0.041390162), (u'was', 0.055589862), (u'worse', 0.098543182), (u'than', 0.13712604), (u'cocaine', 0.16046187), (u'withdrawal', 0.10660571)]\n",
      "\n",
      "@MHchat Hopefully I would love to chat or talk by skype with you and your team. I am on 1 med Saphris. I lost 10 pounds 2 months ago.\n",
      "hopefully i would love to chat or talk by skype with you and your team . i am on 1 med saphris . i lost 10 pounds 2 months ago .\n",
      "[(u'hopefully', 0.0055398573), (u'i', 0.0071326336), (u'would', 0.0092880195), (u'love', 0.011051367), (u'to', 0.012663747), (u'chat', 0.013381886), (u'or', 0.013299225), (u'talk', 0.012676121), (u'by', 0.011051963), (u'skype', 0.0099753477), (u'with', 0.0091936709), (u'you', 0.0090677198), (u'and', 0.0095026484), (u'your', 0.012780122), (u'team', 0.016733894), (u'i', 0.020233339), (u'am', 0.025848906), (u'on', 0.034487411), (u'med', 0.045544047), (u'i', 0.066282071), (u'lost', 0.12076469), (u'pounds', 0.16592148), (u'months', 0.16285105), (u'ago', 0.10101194)]\n",
      "\n",
      "@Jonny_Wags @Hey_Jeffrey Realtalk: until I started taking Wellbutrin, Effexor robbed me of the ability to cum\n",
      "realtalk : until i started taking wellbutrin , effexor robbed me of the ability to cum\n",
      "[(u'realtalk', 0.0042473697), (u'until', 0.00660779), (u'i', 0.0126687), (u'started', 0.031030977), (u'taking', 0.090900138), (u'wellbutrin', 0.19097875), (u'effexor', 0.23055312), (u'robbed', 0.1437932), (u'me', 0.066060938), (u'of', 0.032564104), (u'the', 0.026488695), (u'ability', 0.029315719), (u'to', 0.032928616), (u'cum', 0.025946239)]\n",
      "\n",
      "@catthoma Right, some SSRIs are used for cataplexy, as is Effexor. Can be tricky to wean off without rebound. #nchat\n",
      "right , some ssris are used for cataplexy , as is effexor . can be tricky to wean off without rebound . nchat\n",
      "[(u'right', 0.0078271143), (u'some', 0.0093738278), (u'ssris', 0.01021813), (u'are', 0.008692014), (u'used', 0.0092824232), (u'for', 0.011592587), (u'cataplexy', 0.018485051), (u'as', 0.027955491), (u'is', 0.039572161), (u'effexor', 0.049265407), (u'can', 0.061158147), (u'be', 0.072773129), (u'tricky', 0.079848327), (u'to', 0.093645662), (u'wean', 0.1096036), (u'off', 0.12483773), (u'without', 0.10848302), (u'rebound', 0.067768663)]\n",
      "\n",
      "I'm void of nicotine and my moods are void of stability.\n",
      "i'm void of nicotine and my moods are void of stability .\n",
      "[(u'i', 0.012736571), (u'm', 0.014300111), (u'void', 0.016281571), (u'of', 0.01784947), (u'nicotine', 0.02263733), (u'and', 0.03638681), (u'my', 0.061922237), (u'moods', 0.1020321), (u'are', 0.12763943), (u'void', 0.14342234), (u'of', 0.11043935), (u'stability', 0.078047626)]\n",
      "\n",
      "@ItsMeCreezy I hate to hear that. Taking seroquel is like swallowing a sleeping pill when u wake up then trying to function normally\n",
      "i hate to hear that . taking seroquel is like swallowing a sleeping pill when u wake up then trying to function normally\n",
      "[(u'i', 0.0023007623), (u'hate', 0.0031096742), (u'to', 0.0039685718), (u'hear', 0.0048593292), (u'that', 0.0065901931), (u'taking', 0.011866897), (u'seroquel', 0.019976515), (u'is', 0.040671978), (u'like', 0.071697913), (u'swallowing', 0.10592704), (u'a', 0.11422338), (u'sleeping', 0.11981774), (u'pill', 0.092195444), (u'when', 0.072234683), (u'u', 0.053614277), (u'wake', 0.047532916), (u'up', 0.04305375), (u'then', 0.040782452), (u'trying', 0.039050363), (u'to', 0.035861846), (u'function', 0.02736206), (u'normally', 0.016728939)]\n",
      "\n",
      "@badboyfloyd_ lmao, i'm prescribed baby. it's for my anxiety. i take seroquel, and celexa with it. i'm a fucking zombie after 9pm.\n",
      "lmao , i'm prescribed baby . it's for my anxiety . i take seroquel , and celexa with it . i'm a fucking zombie after 9pm .\n",
      "[(u'lmao', 0.0054133558), (u'i', 0.0061587468), (u'm', 0.00739442), (u'prescribed', 0.0079100244), (u'baby', 0.0083177648), (u'it', 0.009674781), (u's', 0.010877417), (u'for', 0.012226529), (u'my', 0.014230953), (u'anxiety', 0.013765919), (u'i', 0.011824182), (u'take', 0.010139314), (u'seroquel', 0.0093311546), (u'and', 0.0090731056), (u'celexa', 0.011256621), (u'with', 0.014139494), (u'it', 0.020027224), (u'i', 0.030517871), (u'm', 0.057133012), (u'a', 0.10824337), (u'fucking', 0.1673795), (u'zombie', 0.19275956), (u'after', 0.13460603), (u'pm', 0.062781461)]\n",
      "\n",
      "Geez this vyvanse makes me talk a mile a minute haha\n",
      "geez this vyvanse makes me talk a mile a minute haha\n",
      "[(u'geez', 0.015933719), (u'this', 0.038538788), (u'vyvanse', 0.095026702), (u'makes', 0.16064031), (u'me', 0.18708317), (u'talk', 0.14321265), (u'a', 0.093162723), (u'mile', 0.062520675), (u'a', 0.04509123), (u'minute', 0.034723435), (u'haha', 0.022063773)]\n",
      "\n",
      "I resent taking olanzapine as it is the side effects of olanzapine that were mistaken for negative symptoms of schizophrenia\n",
      "i resent taking olanzapine as it is the side effects of olanzapine that were mistaken for negative symptoms of schizophrenia\n",
      "[(u'i', 0.011943937), (u'resent', 0.023130855), (u'taking', 0.040553417), (u'olanzapine', 0.051375423), (u'as', 0.055406991), (u'it', 0.051833853), (u'is', 0.042364269), (u'the', 0.036165792), (u'side', 0.031160098), (u'effects', 0.025562199), (u'of', 0.023806291), (u'olanzapine', 0.023451695), (u'that', 0.026403466), (u'were', 0.035310827), (u'mistaken', 0.051761713), (u'for', 0.072432064), (u'negative', 0.095983937), (u'symptoms', 0.10333137), (u'of', 0.076612085), (u'schizophrenia', 0.042998504)]\n",
      "\n",
      "@chenoite @CSB_22 yes def eat or the cipro will tear u up and feel better :-)\n",
      "yes def eat or the cipro will tear u up and feel better :-)\n",
      "[(u'yes', 0.01773406), (u'def', 0.033108551), (u'eat', 0.050963402), (u'or', 0.070885345), (u'the', 0.086224727), (u'cipro', 0.11110215), (u'will', 0.11637966), (u'tear', 0.12224646), (u'u', 0.077536479), (u'up', 0.064282037), (u'and', 0.044505265), (u'feel', 0.040801324), (u'better', 0.028124843)]\n",
      "\n",
      "Seroquel left me with sleep paralysis. Abilify left me with occasional muscle spasms. I've been off of both for nearly a decade.\n",
      "seroquel left me with sleep paralysis . abilify left me with occasional muscle spasms . i've been off of both for nearly a decade .\n",
      "[(u'seroquel', 0.0044554803), (u'left', 0.011512848), (u'me', 0.031335451), (u'with', 0.055309232), (u'sleep', 0.085390337), (u'paralysis', 0.075505272), (u'abilify', 0.051530018), (u'left', 0.041591942), (u'me', 0.058638342), (u'with', 0.087637015), (u'occasional', 0.14325459), (u'muscle', 0.15215223), (u'spasms', 0.090382867), (u'i', 0.034616493), (u've', 0.014619342), (u'been', 0.0063270046), (u'off', 0.0037158271), (u'of', 0.0028715273), (u'both', 0.0030352785), (u'for', 0.0040497822), (u'nearly', 0.0066579944), (u'a', 0.0090038385), (u'decade', 0.0086643966)]\n",
      "\n",
      "Not hungry but eating anyway. Thank you Quetiapine you utter cunt.\n",
      "not hungry but eating anyway . thank you quetiapine you utter cunt .\n",
      "[(u'not', 0.030777596), (u'hungry', 0.081746824), (u'but', 0.13778165), (u'eating', 0.13068721), (u'anyway', 0.074921526), (u'thank', 0.049246874), (u'you', 0.043843642), (u'quetiapine', 0.059302263), (u'you', 0.087205566), (u'utter', 0.10177842), (u'cunt', 0.068687834)]\n",
      "\n",
      "#bpdchat I take seroquel at night, high dose. It knocks me out\n",
      "bpdchat i take seroquel at night , high dose . it knocks me out\n",
      "[(u'i', 0.0030485112), (u'take', 0.0049645882), (u'seroquel', 0.010166538), (u'at', 0.019948851), (u'night', 0.048363961), (u'high', 0.086747997), (u'dose', 0.13987948), (u'it', 0.18492067), (u'knocks', 0.19571111), (u'me', 0.13544595), (u'out', 0.069649994)]\n",
      "\n",
      "@boatsnkrose They are on to you. Poppin' metoprolol and she sweatin'.\n",
      "they are on to you . poppin ' metoprolol and she sweatin ' .\n",
      "[(u'they', 0.020242445), (u'are', 0.038299292), (u'on', 0.069772176), (u'to', 0.099858113), (u'you', 0.093964949), (u'poppin', 0.078929782), (u'metoprolol', 0.069584198), (u'and', 0.072748177), (u'she', 0.071800195), (u'sweatin', 0.062447757)]\n",
      "\n",
      "@disabledmedic Quetiapine perhaps gives most dramatic effect for single low dose. No, pts are not being lazy in bed 20 hours a day, asleep!\n",
      "quetiapine perhaps gives most dramatic effect for single low dose . no , pts are not being lazy in bed 20 hours a day , asleep !\n",
      "[(u'quetiapine', 0.0074075605), (u'perhaps', 0.01542102), (u'gives', 0.027842017), (u'most', 0.031398691), (u'dramatic', 0.028881466), (u'effect', 0.025450937), (u'for', 0.020440742), (u'single', 0.020067034), (u'low', 0.020363752), (u'dose', 0.020871023), (u'no', 0.017318921), (u'pts', 0.015031801), (u'are', 0.01208755), (u'not', 0.013622396), (u'being', 0.016575122), (u'lazy', 0.030209431), (u'in', 0.044875991), (u'bed', 0.078144476), (u'hours', 0.11220169), (u'a', 0.15290962), (u'day', 0.13230826), (u'asleep', 0.084500402)]\n",
      "\n",
      "I'm now back on the olanzapine along side lithium. Ugh. #helloweightgain\n",
      "i'm now back on the olanzapine along side lithium . ugh . helloweightgain\n",
      "[(u'i', 0.0050808098), (u'm', 0.0072230478), (u'now', 0.012419007), (u'back', 0.020560347), (u'on', 0.039546367), (u'the', 0.062039796), (u'olanzapine', 0.10572772), (u'along', 0.15239334), (u'side', 0.20658912), (u'lithium', 0.15762755), (u'ugh', 0.091444314)]\n",
      "\n",
      "@TheMartinNewman to be honest I've had worse. On fluoxetine I was convinced there was a plot to steal my thoughts... !\n",
      "to be honest i've had worse . on fluoxetine i was convinced there was a plot to steal my thoughts ... !\n",
      "[(u'to', 0.010112736), (u'be', 0.015859459), (u'honest', 0.025181279), (u'i', 0.035925731), (u've', 0.056079365), (u'had', 0.075297944), (u'worse', 0.082092173), (u'on', 0.06851057), (u'fluoxetine', 0.042526376), (u'i', 0.025868434), (u'was', 0.020834656), (u'convinced', 0.022363998), (u'there', 0.026255006), (u'was', 0.033280045), (u'a', 0.035942931), (u'plot', 0.038238112), (u'to', 0.047131006), (u'steal', 0.065765366), (u'my', 0.079500861), (u'thoughts', 0.072972305)]\n",
      "\n",
      "So, I lasted 16 days on Seroquel. I couldn't handle the awful side effects. Constantly dizzy and lightheadeded & a myriad of other bad stuff\n",
      "so , i lasted 16 days on seroquel . i couldn't handle the awful side effects . constantly dizzy and lightheadeded & a myriad of other bad stuff\n",
      "[(u'so', 0.0070936494), (u'i', 0.012333947), (u'lasted', 0.019084178), (u'days', 0.022678588), (u'on', 0.02373316), (u'seroquel', 0.022591246), (u'i', 0.020871282), (u'could', 0.025156271), (u'not', 0.028189704), (u'handle', 0.034454852), (u'the', 0.039677612), (u'awful', 0.061192498), (u'side', 0.084645867), (u'effects', 0.12046865), (u'constantly', 0.14014427), (u'dizzy', 0.12090128), (u'and', 0.063559577), (u'a', 0.035198633), (u'myriad', 0.018577063), (u'of', 0.015249996), (u'other', 0.015374437), (u'bad', 0.018305883), (u'stuff', 0.015531111)]\n",
      "\n",
      "@theotherrift can also get \"extrapyramidal symptoms\" ie tremor from olanzapine.\n",
      "can also get \" extrapyramidal symptoms \" ie tremor from olanzapine .\n",
      "[(u'can', 0.0057869595), (u'also', 0.01688564), (u'get', 0.055329461), (u'extrapyramidal', 0.12898083), (u'symptoms', 0.21096575), (u'ie', 0.2112307), (u'tremor', 0.16249923), (u'from', 0.087852158), (u'olanzapine', 0.043740693)]\n",
      "\n",
      "Zoloft was just as bad as Effexor. It made me more depressed and more suicidal. I don't want it.\n",
      "zoloft was just as bad as effexor . it made me more depressed and more suicidal . i don't want it .\n",
      "[(u'zoloft', 0.0039429436), (u'was', 0.0062630987), (u'just', 0.012825229), (u'as', 0.021724584), (u'bad', 0.044675138), (u'as', 0.078497715), (u'effexor', 0.12798396), (u'it', 0.15731691), (u'made', 0.15341225), (u'me', 0.097666599), (u'more', 0.065394081), (u'depressed', 0.047534168), (u'and', 0.037009515), (u'more', 0.030971549), (u'suicidal', 0.021219434), (u'i', 0.012639901), (u'do', 0.0092210639), (u'not', 0.0084445504), (u'want', 0.0093417643), (u'it', 0.010764644)]\n",
      "\n",
      "I think baclofen might make me a bigger asshole than usual. :/\n",
      "i think baclofen might make me a bigger asshole than usual . :/\n",
      "[(u'i', 0.0048517524), (u'think', 0.011471033), (u'baclofen', 0.027296575), (u'might', 0.060037721), (u'make', 0.12298097), (u'me', 0.17261302), (u'a', 0.17253777), (u'bigger', 0.15370177), (u'asshole', 0.1097791), (u'than', 0.064296), (u'usual', 0.034588289)]\n",
      "\n",
      "@sickleSTRONG Word to the wise: Don't swallow Cipro AT ALL!!! It is POISON and can cripple you for life! Is your situation life or death?\n",
      "word to the wise : don't swallow cipro at all !!! it is poison and can cripple you for life ! is your situation life or death ?\n",
      "[(u'word', 0.0061661662), (u'to', 0.008350906), (u'the', 0.011438706), (u'wise', 0.015513553), (u'do', 0.022506999), (u'not', 0.034827448), (u'swallow', 0.044649985), (u'cipro', 0.047734417), (u'at', 0.045893829), (u'all', 0.04480404), (u'it', 0.039090294), (u'is', 0.033399694), (u'poison', 0.026524417), (u'and', 0.020635113), (u'can', 0.016059751), (u'cripple', 0.014804131), (u'you', 0.015920999), (u'for', 0.019278508), (u'life', 0.025333265), (u'is', 0.033463169), (u'your', 0.047212113), (u'situation', 0.068226725), (u'life', 0.10137281), (u'or', 0.10396487), (u'death', 0.076938279)]\n",
      "\n",
      "Oh... oh my hair is... definitely falling out. ._. I just noticed it starting tonight. Google tells me other people on Lamictal have this.\n",
      "oh ... oh my hair is ... definitely falling out . ._. i just noticed it starting tonight . google tells me other people on lamictal have this .\n",
      "[(u'oh', 0.0097653689), (u'oh', 0.021753684), (u'my', 0.052816249), (u'hair', 0.10953553), (u'is', 0.16997308), (u'definitely', 0.16583808), (u'falling', 0.11509524), (u'out', 0.056288499), (u'i', 0.030188888), (u'just', 0.021206295), (u'noticed', 0.02099764), (u'it', 0.021159956), (u'starting', 0.022253236), (u'tonight', 0.018854436), (u'google', 0.015844705), (u'tells', 0.014786732), (u'me', 0.016805245), (u'other', 0.017335838), (u'people', 0.016149912), (u'on', 0.014230317), (u'lamictal', 0.011751533), (u'have', 0.010199437), (u'this', 0.0091841398)]\n",
      "\n",
      "EVERYONE: I HAVE A DRUG ADDICTION TO SEROQUEL, I TAKE 6 A YEAR, HELP ME STOP\n",
      "everyone : i have a drug addiction to seroquel , i take 6 a year , help me stop\n",
      "[(u'everyone', 0.010136695), (u'i', 0.019687574), (u'have', 0.048199546), (u'a', 0.11436229), (u'drug', 0.17634612), (u'addiction', 0.16735251), (u'to', 0.10096144), (u'seroquel', 0.042797901), (u'i', 0.019508196), (u'take', 0.013742006), (u'a', 0.01298077), (u'year', 0.017980831), (u'help', 0.02854888), (u'me', 0.042174213), (u'stop', 0.041398551)]\n",
      "\n",
      "This night of no sleep is brought to you by Vyvanse.\n",
      "this night of no sleep is brought to you by vyvanse .\n",
      "[(u'this', 0.011264832), (u'night', 0.026519336), (u'of', 0.060540952), (u'no', 0.11986481), (u'sleep', 0.17325439), (u'is', 0.15920562), (u'brought', 0.11546188), (u'to', 0.080003306), (u'you', 0.058183916), (u'by', 0.038944189), (u'vyvanse', 0.028905399)]\n",
      "\n",
      "Had a great few hours on my bike but exercise drives my #olanzapine munchies. Getting fed up with not being able to fit into summer wardrobe\n",
      "had a great few hours on my bike but exercise drives my #olanzapine munchies . getting fed up with not being able to fit into summer wardrobe\n",
      "[(u'had', 0.0042574108), (u'a', 0.0069382624), (u'great', 0.010665298), (u'few', 0.013136447), (u'hours', 0.015263585), (u'on', 0.016370872), (u'my', 0.01724286), (u'bike', 0.016854389), (u'but', 0.018300222), (u'exercise', 0.026106874), (u'drives', 0.045156933), (u'my', 0.092467569), (u'olanzapine', 0.16690353), (u'munchies', 0.20788772), (u'getting', 0.14808133), (u'fed', 0.066870391), (u'up', 0.025569776), (u'with', 0.011279134), (u'not', 0.0069738659), (u'being', 0.0061773271), (u'able', 0.0069848858), (u'to', 0.0081945257), (u'fit', 0.01058119), (u'into', 0.012644526), (u'summer', 0.01228539), (u'wardrobe', 0.009430985)]\n",
      "\n",
      "Dabigatran not working in this obese pt, maybe contributing to his stroke. Saved by tPA.... Speechless http://www.nejm.org/doi/full/10.1056/NEJMc1215900?af=R&rss=currentIssue&utm_source=feedly ...\n",
      "dabigatran not working in this obese pt , maybe contributing to his stroke . saved by tpa .... speechless ...\n",
      "[(u'dabigatran', 0.0052047754), (u'not', 0.0072228187), (u'working', 0.011963772), (u'in', 0.01932448), (u'this', 0.032065615), (u'obese', 0.049747445), (u'pt', 0.068043664), (u'maybe', 0.086277351), (u'contributing', 0.098025359), (u'to', 0.095135741), (u'his', 0.090402566), (u'stroke', 0.083274893), (u'saved', 0.075953275), (u'by', 0.067151435), (u'tpa', 0.053157374), (u'speechless', 0.037207372)]\n",
      "\n",
      "It appears that my twitter addiction may have just been a side effect of my nicotine lozenge addiction.\n",
      "it appears that my twitter addiction may have just been a side effect of my nicotine lozenge addiction .\n",
      "[(u'it', 0.0084935166), (u'appears', 0.017018769), (u'that', 0.031193849), (u'my', 0.049730673), (u'twitter', 0.0514591), (u'addiction', 0.049638581), (u'may', 0.035914294), (u'have', 0.034503128), (u'just', 0.040267661), (u'been', 0.069534294), (u'a', 0.10265416), (u'side', 0.12579571), (u'effect', 0.090415157), (u'of', 0.051761162), (u'my', 0.035944134), (u'nicotine', 0.035177149), (u'lozenge', 0.036204163), (u'addiction', 0.037508387)]\n",
      "\n",
      "Do you know how badly I want a cigarette right now? But no. I manfully suffer through nicotine withdrawal--all for you #sacrifice\n",
      "do you know how badly i want a cigarette right now ? but no . i manfully suffer through nicotine withdrawal -- all for you #sacrifice\n",
      "[(u'do', 0.0045976918), (u'you', 0.0079203192), (u'know', 0.012832495), (u'how', 0.014590143), (u'badly', 0.014744119), (u'i', 0.012462822), (u'want', 0.013791085), (u'a', 0.014579267), (u'cigarette', 0.01535729), (u'right', 0.016182683), (u'now', 0.017675551), (u'but', 0.02474967), (u'no', 0.037186924), (u'i', 0.052465748), (u'manfully', 0.083541378), (u'suffer', 0.13201994), (u'through', 0.149168), (u'nicotine', 0.12687291), (u'withdrawal', 0.092615217), (u'all', 0.052825138), (u'for', 0.032742403), (u'you', 0.021509141), (u'sacrifice', 0.015202993)]\n",
      "\n",
      "Me: Why have I been sectioned, what psychotic symptoms do I have? Psychiatrist: Dancing. I am now addicted to the antipsychotic olanzapine\n",
      "me : why have i been sectioned , what psychotic symptoms do i have ? psychiatrist : dancing . i am now addicted to the antipsychotic olanzapine\n",
      "[(u'me', 0.010281218), (u'why', 0.016781131), (u'have', 0.020585548), (u'i', 0.021681948), (u'been', 0.028385073), (u'sectioned', 0.038863163), (u'what', 0.053009018), (u'psychotic', 0.062238779), (u'symptoms', 0.054084964), (u'do', 0.03608105), (u'i', 0.024989069), (u'have', 0.020731498), (u'psychiatrist', 0.019462056), (u'dancing', 0.025796661), (u'i', 0.037219707), (u'am', 0.058582399), (u'now', 0.069231093), (u'addicted', 0.079070583), (u'to', 0.073022172), (u'the', 0.070953548), (u'antipsychotic', 0.055649202), (u'olanzapine', 0.043279584)]\n",
      "\n",
      "Rivaroxaban diary day 22. Am beginning to think all pains from pressure on that part of body are due to fluid retention.\n",
      "rivaroxaban diary day 22 . am beginning to think all pains from pressure on that part of body are due to fluid retention .\n",
      "[(u'rivaroxaban', 0.0050238119), (u'diary', 0.011867906), (u'day', 0.024392072), (u'am', 0.033591494), (u'beginning', 0.051810198), (u'to', 0.076329835), (u'think', 0.13174644), (u'all', 0.1640451), (u'pains', 0.14802273), (u'from', 0.065732077), (u'pressure', 0.02557233), (u'on', 0.0099377725), (u'that', 0.0059114825), (u'part', 0.0059727249), (u'of', 0.0084833279), (u'body', 0.017242679), (u'are', 0.02831131), (u'due', 0.048097633), (u'to', 0.052629493), (u'fluid', 0.042712893), (u'retention', 0.020299071)]\n",
      "\n",
      "People taking #quetiapine - does this need to sleep 24/7 go eventually? Cos this is not sustainable beyond the short term.\n",
      "people taking #quetiapine - does this need to sleep 24/7 go eventually ? cos this is not sustainable beyond the short term .\n",
      "[(u'people', 0.014270274), (u'taking', 0.018305406), (u'quetiapine', 0.019810865), (u'does', 0.019087888), (u'this', 0.020181548), (u'need', 0.028732397), (u'to', 0.057579074), (u'sleep', 0.11487155), (u'go', 0.15343244), (u'eventually', 0.14343622), (u'cos', 0.086477458), (u'this', 0.048940841), (u'is', 0.031403977), (u'not', 0.024233891), (u'sustainable', 0.02013349), (u'beyond', 0.022332421), (u'the', 0.024854444), (u'short', 0.0271818), (u'term', 0.024818974)]\n",
      "\n",
      "Plus this antibiotic is making me stupid and clumsy. Cipro is evil but the fever is gone.\n",
      "plus this antibiotic is making me stupid and clumsy . cipro is evil but the fever is gone .\n",
      "[(u'plus', 0.0041822079), (u'this', 0.0086642029), (u'antibiotic', 0.02282585), (u'is', 0.050585747), (u'making', 0.099929735), (u'me', 0.12040611), (u'stupid', 0.10806019), (u'and', 0.089865252), (u'clumsy', 0.075503655), (u'cipro', 0.055424418), (u'is', 0.047096711), (u'evil', 0.036934804), (u'but', 0.034894396), (u'the', 0.03996418), (u'fever', 0.051002666), (u'is', 0.047994658), (u'gone', 0.037175167)]\n",
      "\n",
      "So unfair, I never get the good side effects of meds. Ativan, Seroquel, & Ambien XR make me feel so drink I cant really walk & Im nauseated\n",
      "so unfair , i never get the good side effects of meds . ativan , seroquel , & ambien xr make me feel so drink i cant really walk & im nauseated\n",
      "[(u'so', 0.0050838967), (u'unfair', 0.0064117606), (u'i', 0.0067954636), (u'never', 0.0066580614), (u'get', 0.0064064274), (u'the', 0.0068208142), (u'good', 0.0070787533), (u'side', 0.0079629915), (u'effects', 0.007557123), (u'of', 0.0079553928), (u'meds', 0.0089375814), (u'ativan', 0.012448064), (u'seroquel', 0.022355234), (u'ambien', 0.04879652), (u'xr', 0.096315071), (u'make', 0.16100882), (u'me', 0.17208944), (u'feel', 0.12667267), (u'so', 0.065477788), (u'drink', 0.030646991), (u'i', 0.014509252), (u'cant', 0.013114734), (u'really', 0.016949313), (u'walk', 0.028484734), (u'im', 0.037075963), (u'nauseated', 0.035142474)]\n",
      "\n",
      "@PArthritis I don't know that one, but metho made me sick everyday I took it. I had to stop. Enbrel has worked wonders for me .. so far\n",
      "i don't know that one , but metho made me sick everyday i took it . i had to stop . enbrel has worked wonders for me .. so far\n",
      "[(u'i', 0.0023339181), (u'do', 0.0034750453), (u'not', 0.0048661609), (u'know', 0.0073580118), (u'that', 0.010192227), (u'one', 0.017398661), (u'but', 0.034637861), (u'metho', 0.082946822), (u'made', 0.17096554), (u'me', 0.22692794), (u'sick', 0.16268881), (u'everyday', 0.063791119), (u'i', 0.024622241), (u'took', 0.013284111), (u'it', 0.012983608), (u'i', 0.014366819), (u'had', 0.017416203), (u'to', 0.016005475), (u'stop', 0.011701964), (u'enbrel', 0.0072828699), (u'has', 0.0062660673), (u'worked', 0.0064203367), (u'wonders', 0.0081989486), (u'for', 0.01072842), (u'me', 0.014626254), (u'so', 0.015572292), (u'far', 0.013237259)]\n",
      "\n",
      "@gastromom WOW...if only more doctors thought like you!! I lost my entire life to twelve Cipro pills.\n",
      "wow ... if only more doctors thought like you !! i lost my entire life to twelve cipro pills .\n",
      "[(u'wow', 0.0047143181), (u'if', 0.0068275994), (u'only', 0.010930494), (u'more', 0.015828237), (u'doctors', 0.021148674), (u'thought', 0.025068957), (u'like', 0.029747508), (u'you', 0.033084519), (u'i', 0.036721174), (u'lost', 0.050242897), (u'my', 0.067122936), (u'entire', 0.089791685), (u'life', 0.10847766), (u'to', 0.12948968), (u'twelve', 0.12322447), (u'cipro', 0.099895492), (u'pills', 0.056077454)]\n",
      "\n",
      "@FriarDanny I appreciate it. I gained over 30lbs with Paxil so I'm trying something different, tired of the appetite side effects.\n",
      "i appreciate it . i gained over 30lbs with paxil so i'm trying something different , tired of the appetite side effects .\n",
      "[(u'i', 0.002841454), (u'appreciate', 0.004849243), (u'it', 0.010696744), (u'i', 0.017204398), (u'gained', 0.027528347), (u'over', 0.027818134), (u'lbs', 0.024708511), (u'with', 0.01625129), (u'paxil', 0.013187601), (u'so', 0.0092400666), (u'i', 0.0082471082), (u'm', 0.010606815), (u'trying', 0.020610703), (u'something', 0.041997049), (u'different', 0.08353506), (u'tired', 0.14446193), (u'of', 0.15042663), (u'the', 0.13999496), (u'appetite', 0.10721061), (u'side', 0.069564141), (u'effects', 0.031108661)]\n",
      "\n",
      "Seroquel aka wake up at 2:30 and waste half your day sleeping.\n",
      "seroquel aka wake up at 2:30 and waste half your day sleeping .\n",
      "[(u'seroquel', 0.023059856), (u'aka', 0.040008467), (u'wake', 0.058458123), (u'up', 0.054804582), (u'at', 0.043938298), (u'and', 0.033829127), (u'waste', 0.037153587), (u'half', 0.056656882), (u'your', 0.10264393), (u'day', 0.1582707), (u'sleeping', 0.15403749)]\n",
      "\n",
      "02.03 Rivaroxaban diary day 20. Some neck pain and legs still weak, but feeling much better. Very warm night.\n",
      "02.03 rivaroxaban diary day 20 . some neck pain and legs still weak , but feeling much better . very warm night .\n",
      "[(u'rivaroxaban', 0.0057155578), (u'diary', 0.01531616), (u'day', 0.038336501), (u'some', 0.074679241), (u'neck', 0.11927328), (u'pain', 0.14836226), (u'and', 0.12835783), (u'legs', 0.12102053), (u'still', 0.08894515), (u'weak', 0.054800615), (u'but', 0.031962965), (u'feeling', 0.020640392), (u'much', 0.015797565), (u'better', 0.016672734), (u'very', 0.02425278), (u'warm', 0.027959883), (u'night', 0.025984809)]\n",
      "\n",
      "I don't know whether my Vyvanse caused my caffeine addiction or caffeine caused my Vyvanse addiction.\n",
      "i don't know whether my vyvanse caused my caffeine addiction or caffeine caused my vyvanse addiction .\n",
      "[(u'i', 0.00061487139), (u'do', 0.00093203306), (u'not', 0.0016067663), (u'know', 0.0037148991), (u'whether', 0.0085813738), (u'my', 0.020563871), (u'vyvanse', 0.042396486), (u'caused', 0.07066635), (u'my', 0.084757723), (u'caffeine', 0.10501073), (u'addiction', 0.11170539), (u'or', 0.10488676), (u'caffeine', 0.10533527), (u'caused', 0.11316284), (u'my', 0.099731728), (u'vyvanse', 0.068774149), (u'addiction', 0.035135567)]\n",
      "\n",
      "Is it hot in here or is my Vyvanse just kicking in?\n",
      "is it hot in here or is my vyvanse just kicking in ?\n",
      "[(u'is', 0.030167313), (u'it', 0.038910016), (u'hot', 0.040158086), (u'in', 0.030696308), (u'here', 0.030539067), (u'or', 0.032847676), (u'is', 0.053591438), (u'my', 0.07479272), (u'vyvanse', 0.1111919), (u'just', 0.1135805), (u'kicking', 0.11474352), (u'in', 0.069912225)]\n",
      "\n",
      "I can only get about 7-8 hours of sleep on my own. But I got at least 16 hours with Seroquel. I now see how people can get addicted.\n",
      "i can only get about 7-8 hours of sleep on my own . but i got at least 16 hours with seroquel . i now see how people can get addicted .\n",
      "[(u'i', 0.0053280178), (u'can', 0.0085727759), (u'only', 0.015206409), (u'get', 0.027964488), (u'about', 0.051252216), (u'hours', 0.082569137), (u'of', 0.098550044), (u'sleep', 0.10337966), (u'on', 0.078098491), (u'my', 0.056412648), (u'own', 0.035653114), (u'but', 0.022400582), (u'i', 0.014412374), (u'got', 0.01197205), (u'at', 0.012425422), (u'least', 0.014114685), (u'hours', 0.017264834), (u'with', 0.016841469), (u'seroquel', 0.013254165), (u'i', 0.009635021), (u'now', 0.007958943), (u'see', 0.0071470249), (u'how', 0.0088174837), (u'people', 0.017018471), (u'can', 0.036562718), (u'get', 0.065982677), (u'addicted', 0.074314423)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(1000):\n",
    "    if len(docs[skf[0][0][i]]) >= 8 and labels[skf[0][0][i]]==1:\n",
    "        print tweets[skf[0][0][i]]\n",
    "        print zhang_clean_texts[skf[0][0][i]]        \n",
    "        print zip(docs[skf[0][0][i]], attentions([X[skf[0][0][i:i+1]]])[0].flatten())\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.09381618],\n",
       "        [ 0.10483222],\n",
       "        [ 0.08684829],\n",
       "        [ 0.05685537],\n",
       "        [ 0.03641567],\n",
       "        [ 0.02486874],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848],\n",
       "        [ 0.02484848]]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asarray(docs[skf[0][0][1:2]])\n",
    "attentions([X[skf[0][0][1:2]]])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
